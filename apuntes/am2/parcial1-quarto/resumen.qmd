--- 
lang: es
author: Ricardo Freccero
toc: true
fig-cap-location: top
format:
  html:
    theme: cosmo
    code-fold: true
    html-math-method: katex
bibliography: bibliografia.bib
jupyter: python3
---

![](./imagenes/logo_utn_frc.jpg)

::: { style="text-align: center" }
::: { style="font-family: serif" }

### UNIVERSIDAD TECNOLÓGICA NACIONAL

#### FACULTAD REGIONAL CORDOBA - EXTENSIÓN ÁULICA BARILOCHE

##### INGENIERÍA EN SISTEMAS DE INFORMACIÓN

###### AÑO LECTIVO 2025

:::

---

# Análisis Matemático 2
### Resumen Primer Parcial

---

:::

<div style="margin-top: 3rem;"></div>

**Profesor:** Mónica Guraya

**Ayudante:** Santiago Ward

<div style="margin-top: 10rem;"></div>

::: { style="text-align: right" }

**Alumno:** Ricardo Freccero

**Número de legajo:** 415753

:::

---

# Conjuntos y puntos
En $\mathbb{R}^{2}$ el **entorno de punto** $P_{0}(x_{0},y_{0})$ y de radio $\delta$ es el conjunto de puntos ubicados en el interior de un círculo de centro $P_{0}$ y radio $\delta$.
En clase, al entorno lo vimo como **Bola**, así que vamos a usar la $B$ para representarlo.

## Punto
Consideramos como punto a cualquier vector del plano o el espacio que tenga origen en el $\vec{O}$.

## Bola abierta
Es el conjunto de puntos ubicados en un círculo de radio $\delta$ alrededor de un punto $P_{0}$.
$$
B(P_{0},\delta)=\left\{(x,y) \;/\; 0\leq \sqrt[]{(x-x_{0})^2-(y-y_{0})^2}<\delta,\delta \in \mathbb{R}^{}\right\}
$$

Otra notación mas facil de entender es la siguiente:
$$
  B(P_{0},\delta)=\left|P-P_{0}\right|<\delta,\delta \in \mathbb{R}^{}
$$

Que podemos interpretar como: la bola abierta $B(P_{0},\delta)$ es el conjunto de todos los puntos $P$ cuya distancia a $P_{0}$ es menor a $\delta$, siendo $\delta$ el radio de un círculo alrededor del punto $P_{0}$.

## Bola abierta reducida
Es lo mismo que la bola abierta, solo que ahora el punto $P_{0}$ no está incluído en el conjunto de puntos.

La denotamos como $B_{0}$ y su ecuación es la siguiente:
$$
  B_{0}(P_{0},\delta)=0<\left|P-P_{0}\right|<\delta,\delta \in \mathbb{R}^{}
$$

## Bola cerrada
Es el conjunto de puntos alrededor del punto $P_{0}$ que cumplen que su distancia es $\leq \delta$. La denotamos como $\overline{B}$.
$$
\overline{B}(P_{0},\delta)=\left|P-P_{0}\right|\leq \delta,\delta \in \mathbb{R}^{}
$$

## Tipos de puntos
Dados un punto $P$ cualquiera y un conjunto no vacío $A$ de números definimos:

### Punto interior
Un punto $P_{0}$ es interior de un conjunto $A$ si existe una bola abierta alrededor de $P_{0}$ que esté totalmente contenida en $A$.
$$
  P_{0} \text{ es punto interior}  \iff  \exists B(P_{0}) \subset A
$$

### Punto de acumulación
Cuando toda bola abierta reducida alrededor de un punto $P_{0}$ contiene puntos de $A$.
$$
P_{0} \text{ es punto de acumulación de } A  \iff  \forall B_{0}(P_{0},\delta): \exists P \;/\; P \in B_{0}(P_{0},\delta) \land P \in A
$$

### Punto aislado
Cuando existe una bola abierta alrededor del punto $P_{0}$ cuya intersección con $A$ es el mismo punto.
$$
P_{0}\text{ es un punto aislado } \iff  \exists B(P_{0}) \;/\; B(P_{0}) \cap A=P_{0}
$$
**Nota:** Fijarse que $P_{0} \in A$. si bien es un punto que está separado del resto de los puntos de $A$, sigue formando parte de ese conjunto.

### Punto exterior
Este es lo mismo que el anterior, pero ahora $P_{0} \notin A$.
$$
  P_{0}\text{ es punto exterior } \iff  \exists B(P_{0}) \;/\; B(P_{0}) \cap A= \left\{\varnothing\right\}
$$

### Punto frontera
Si hay una bola alrededor de un punto $P_{0}$ que contiene tanto puntos que pertenecen a $A$, como puntos que no pertenecen a $A$.
$$
  P_{0}\text{ es punto frontera } \iff  \forall B(P_{0})=\begin{cases}
     \exists P_{1} \in B(P_{0}) \land P_{1} \in A \\
     \exists P_{2} \in B(P_{0}) \land P_{2} \notin A
  \end{cases}
$$

### Frontera de un conjunto
Es el conjunto de todos los puntos frontera de un conjunto $A$.

## Conjuntos
### Conjunto abierto
Es un conjunto cuyos puntos son todos interiores. No hay puntos frontera.

### Conjunto cerrado
Es un conjunto que contiene todos sus puntos de acumulación, es decir, contiene sus puntos interiores y contiene sus puntos frontera.

### Conjunto acotado
Es un conjunto para el cual es posible hallar un valor $M$ que es mayor que el módulo de cualquier punto $P_{0}$ de $A$.
$$
M \in \mathbb{R}^{+} \;/\; \left|P_{0}\right|<M,\forall P_{0} \in A
$$
Tambien lo podemos escribir de la siguiente forma
$$
\forall P_{0} \in A: \exists M \in \mathbb{R}^{+} \;/\; \left|P_{0}\right|<M
$$

### Complemento de un conjunto
El complemento de un conjunto $A$ es el conjunto que contiene todos los elementos del conjunto universal de $A$ que no pertenecen a $A$.

### Conjunto conexo
Un conjunto es conexo si cualquier par de puntos del conjunto puede ser unido por un camino formado por sementos de recta contenidos en $A$.

### Conjunto simplemente conexo
Es cuando cualquier curva cerrada contenida en el conjunto tiene su interior totalmente contenido en el conjunto.

# Funciones {#sec-funciones}
Existen varios tipos de funciones. Nosotros hasta ahora veníamos trabajando con funciones de una sola variable. Estas funciones se llaman **funciones escalares**, ya que son de la forma $f:\mathbb{R}^{}  \to \mathbb{R}^{}$.

Pero existen otros tres tipos de funciones:

- Funciones de varias variables que devuelven un escalar: Se llaman **campos escalares** y son de la forma $f:\mathbb{R}^{n} \to \mathbb{R}^{}$. La palabra *campo* se usa porque ahora estamos hablando de regiones del espacio: el argumento de la función ya no es un escalar, sino que es un vector de dimensión $n$, y ese vector pertenece al *campo*, o el espacio, $\mathbb{R}^{n}$.

  Una función de este estilo se vería como $f(x_{1},x_{2},\dots ,x_{n})=y$, con $y \in \mathbb{R}^{}$.

- Funciones de una sola variable que devuleven vectores: Se llaman **funciones vectoriales** y son de la forma $f:\mathbb{R}^{} \to \mathbb{R}^{m}$.
  
  Un ejemplo de una función vectorial sería $f(x)=(y_{1}, y_{2}, \dots , y_{n})$, con $x \in \mathbb{R}^{}$

- Funciones de varias variables que devuelven vectores: Se llaman **campos vectoriales** y son de la forma $f:\mathbb{R}^{n} \to \mathbb{R}^{m}$. 

  Un campo vectorial se escribe así $f(x_{1}, x_{2}, \dots , x_{n})=(y_{1},y_{2},\dots ,y_{n})$.

  Otra forma que se suele usar bastante, especialmente cuando empecemos a usar matrices es la forma $f(x_{1}, x_{2}, \dots , x_{n}) = (f_{1}(x_{1}, x_{2}, \dots , x_{n}), f_{2}(x_{1}, x_{2}, \dots , x_{n}), \dots ,f_{m}(x_{1}, x_{2}, \dots , x_{n}))$. Esta forma es literalmente lo mismo que la anterior solo que está escrito distinto, pero en realidad $y_{1} = f_{1}(x_{1}, x_{2}, \dots , x_{n})$, lo mismo para $y_{2}$ y lo mismo para todos los $y$ que hayan del lado izquierdo.

## Funciones implícitas y explícitas
Esto también ya lo vimos en análisis pero está bueno recordarlo. Las funciones con las que vamos a trabajar, vamos a ver que pueden estar representadas de dos maneras distintas.

### Función explícita
Una función se dice que está dada en su forma explícita cuando la variable **dependiente** está despejada, y la función está expresada directamente en términos de la/s variables independientes.

Por ejemplo, supongamos que tenemos una función escalar $f:\mathbb{R}^{} \to \mathbb{R}^{}$. La función está dada en su forma explícita si está escrita de la forma $f(x)=y$.

Otro ejemplo podría ser si tenemos el campo escalar $g:\mathbb{R}^{5} \to \mathbb{R}^{}$. Si $g$ está escrita como $g(x_{1}, x_{2}, x_{3}, x_{4}, x_{5})=y$, entonces está dada en su forma explícita.

### Función implícita{#sec-implicita}
Una función se dice que está dada de forma implícita cuando la variable dependiente no está despejada.

Por ejemplo, supongamos que tenemos una función $f:\mathbb{R}^{2} \to \mathbb{R}^{} \;/\; f = x^2 + 2y - 3z$. Esta función está dada en su forma implícita, ya que la variable $z$, que es la variable dependiente no está despejada en la ecuación de la función.

Las funciones implícitas las vamos a usar un montón, Y ENTRA SÍ O SÍ EN EL PARCIAL. 

Hay veces, como en el ejemplo anterior, que es fácil hacer el pasaje de una función dada en su forma implícita a su forma explícita. Lo único que hay que hacer es despejar $z$ y listo. En el ejemplo anterior, la función $f$ escrita en su forma explícita sería $f(x,y)=\frac{x^2+2y}{3}$. Pero hay muchas otras veces, **y va a pasar en el parcial** que nos dan una función implícita y es literalmente imposible despejar la variable dependiente. En ese caso hay que trabajar con la función implícita nomas, pero ya lo vamos a ver cuando lleguemos. Por ahora solo hay que saber que existen.

## Líneas o Curvas de Nivel
Una curva de nivel para una función $z=f(x,y)$ es el conjunto de todos los puntos $(x,y)$ en los que la función toma el mismo valor $f(x,y)=k$, con $k \in \mathbb{R}^{}$.

Una función $z=f(x,y)$ es un campo escalar $f:\mathbb{R}^{2} \to R$ que describe una superficie. Por ejemplo, la función $z=f(x,y)=x^2+y^2$ es la ecuación de un paraboloide circular que tiene su vertice en el origen de coordenadas. Si nosotros decimos ahora que $z=4$ (por tirar un número), la función queda como $x^2+y^2=4$, y eso es la ecuación de una circunferencia de radio 2. Entonces, el conjunto de todos los puntos que forman una circunferencia de radio 2, con centro en el origen, es la curva de nivel de $f(x,y)=4$.

Podemos pensar la curva de nivel como la proyección de la superficie en $f(x,y)=k$ sobre el plano $xy$.

```{python}
import numpy as np
import plotly.graph_objects as go

# Superficie: z = f(x,y)
x = np.linspace(-2, 2, 20)
y = np.linspace(-2, 2, 20)
x, y = np.meshgrid(x, y)
z = x**2 + y**2

# Curva de nivel f(x,y)=4
theta = np.linspace(0, 2 * np.pi, 200)
x_curva = 2 * np.cos(theta)
y_curva = 2 * np.sin(theta)
z_curva = np.full_like(theta, 4)
z_proy = np.full_like(theta, 0)  # para la proyección sobre el plano xy

fig = go.Figure()

# Grafico la superficie
fig.add_trace(go.Surface(x=x, y=y, z=z, colorscale="Viridis", opacity=0.5, showscale=False))

# Grafico la curva de nivel sobre la superficie
fig.add_trace(go.Scatter3d(
  x=x_curva,
  y=y_curva,
  z=z_curva,
  mode="lines",
  line=dict(color="blue", width=4),
  name="Curva de nivel"
))

# Grafico la proyección de la curva de nivel sobre el plano xy
fig.add_trace(go.Scatter3d(
  x=x_curva,
  y=y_curva,
  z=z_proy,
  mode="lines",
  line=dict(color="black", width=4),
  name="Proyección de la curva de nivel"
))

# Ajusto la imagen del gráfico
fig.update_layout(
  scene=dict(aspectmode="cube")
)
```
<!-- Hay un bug y tengo que poner este comentario sí o sí. No sé qué onda. Si no pongo el comentario, la siguiente sección se renderiza al principio del documento. -->

## Superficies de nivel
En el caso de funciones de 3 variables independientes, osea campos escalares que van de $f:\mathbb{R}^{3} \to \mathbb{R}^{}$, podemos definir superficies de nivel.

Para una función $w=f(x,y,z)$, una superficie de nivel es el conjunto de todos los puntos $(x,y,z)$ en los que la función toma el mismo valor $f(x,y,z)=k$, con $k \in \mathbb{R}^{}$.

En este caso no podemos hacer un gráfico como el anterior ya que al tener una función de 3 variables, necesitamos 4 dimensiones para graficarla. Lo que sí podemos hacer es graficar la superficie de nivel.

## Incrementos de una función
Cuando hablamos de incrementos de una función, hacemos referencia a cómo varía la función al desplazarnos en las distintas direcciones.

```{python}
#| label: fig-incrementos
#| fig-cap: Incrementos de una función (adaptado de @am2monllor [p. 14])

# Superficie: z = f(x, y)
x = np.linspace(0, 1, 20)
y = np.linspace(0, 1, 20)
x, y = np.meshgrid(x, y)
z = -(x-1)**2 - (y-1)**2 + 2

# Puntos importantes
points = {
    "M": (0.6, 0.6, -(0.6-1)**2 - (0.6-1)**2 + 2),
    "N": (1, 0.6, -(0.6-1)**2 + 2),
    "T": (0.6, 1, -(0.6-1)**2 + 2),
    "Q": (1, 1, 2),
    "N1": (1, 0.6, -(0.6-1)**2 - (0.6-1)**2 + 2),
    "T1": (0.6, 1, -(0.6-1)**2 - (0.6-1)**2 + 2),
    "Q1": (1, 1, -(0.6-1)**2 - (0.6-1)**2 + 2),
    "P": (0.6, 0.6, 0),
    "P1": (1, 0.6, 0),
    "P2": (0.6, 1, 0),
    "P0": (1, 1, 0),
}

aristas = [
    ("P", "P1"), ("P1", "P0"), ("P0", "P2"), ("P2", "P"),
    ("M", "N1"), ("N1", "Q1"), ("Q1", "T1"), ("T1", "M"),
    ("P", "M"), ("P1", "N1"), ("P0", "Q1"), ("P2", "T1"),
]

# Crear figura
fig = go.Figure()

# Superficie
fig.add_trace(go.Surface(x=x, y=y, z=z, colorscale='Viridis', opacity=0.5, showscale=False))

# Puntos
for name, (x_, y_, z_) in points.items():
    fig.add_trace(go.Scatter3d(
        x=[x_], y=[y_], z=[z_],
        mode='markers+text',
        marker=dict(size=2, color='black'),
        text=[name],
        textposition='middle right',
        showlegend=False,
    ))

# Dibujo las proyecciones
for inicio, fin in aristas:
    x0, y0, z0 = points[inicio]
    x1, y1, z1 = points[fin]
    fig.add_trace(go.Scatter3d(
	x=[x0, x1],
	y=[y0, y1],
	z=[z0, z1],
	mode="lines",
	line=dict(color="gray", width=2, dash="dash"),
	showlegend=False,
    ))

# Línea entre puntos P → P0)
fig.add_trace(go.Scatter3d(
    x=[points["P"][0], points["P0"][0]],
    y=[points["P"][1], points["P0"][1]],
    z=[points["P"][2], points["P0"][2]],
    mode='lines',
    line=dict(color='blue', width=4, dash="longdash"),
    name="ΔS"
))

# Incremento parcial de x
fig.add_trace(go.Scatter3d(
    x=[points["N1"][0], points["N"][0]],
    y=[points["N1"][1], points["N"][1]],
    z=[points["N1"][2], points["N"][2]],
    mode="lines",
    line=dict(color="yellow", width=4),
    name="$\\Delta_{x} z$",
))
# Incremento parcial de y
fig.add_trace(go.Scatter3d(
    x=[points["T1"][0], points["T"][0]],
    y=[points["T1"][1], points["T"][1]],
    z=[points["T1"][2], points["T"][2]],
    mode="lines",
    line=dict(color="green", width=4),
    name="$\\Delta_{y} z$",
))
# Incremento total de z
fig.add_trace(go.Scatter3d(
    x=[points["Q1"][0], points["Q"][0]],
    y=[points["Q1"][1], points["Q"][1]],
    z=[points["Q1"][2], points["Q"][2]],
    mode="lines",
    line=dict(color="red", width=4),
    name="$\\Delta z$",
))

fig.update_layout(scene=dict(
    xaxis_title='x',
    yaxis_title='y',
    zaxis_title='z',
    aspectratio=dict(x=1, y=1, z=1),
))
```

En la @fig-incrementos podemos ver que la curva $MN$, que es la intersección de la superficie $z=f(x,y)$ y el plano $y=cte$, vemos que si nos movemos sobre ella, $z$ varía solo en función de $x$.

Si nos movemos en el eje $x$ una distancia $\Delta x$, la variación de $z$ es lo que se conoce como **incremento parcial de $z$ respecto de $x$** y lo denotamos como $\Delta_{x} z$ (es el segmento $\overline{NN_{1}}$ de la @fig-incrementos).
$$
  \Delta_{x} z = f(x + \Delta x, y) - f(x,y)
$$

Si en cambio, consideramos a $x=cte$ y nos vamos moviendo sobre el eje $y$, la variación de $z$ es el **incremento parcial de $z$ respecto de $y$** y lo denotamos como $\Delta_{y} z$ (es el segmento $\overline{TT_{1}}$)
$$
  \Delta_{x} z = f(x, y + \Delta y) - f(x,y)
$$

Por último, si incrementamos simultaneamente a $x$ en $\Delta x$ y a $y$ en $\Delta y$, obtenemos el **incremento total de la función**, lo denotamos como $\Delta z$ (segmento $\overline{QQ_{1}}$)
$$
  \Delta z = f(x + \Delta x, y + \Delta y) - f(x,y)
$${#eq-incremento-total-z}

# Límites
Ahora ya sabemos todo lo que hay que saber para poder empezar a estudiar las funciones de análisis 2.

::: {.callout-note title="Definición"}
Dada una función $z=f(x,y)$, se define el límite de esa función cuadno $P(x,y)$ tiende a $P_{0}(x_{0},y_{0})$ de la siguiente manera:

*El límite de $f(x,y)$ es igual a $L$ si, para cualquier número $\varepsilon>0$ existe un número $\delta>0$ tal que, si la distancia del punto $P(x,y)$ a $P_{0}(x_{0},y_{0})$ es menor a $\delta$, entonces la distancia entre $f(x,y)$ y $L$ es menor a $\varepsilon$, con $P(x,y)\neq P_{0}(x_{0},y_{0})$*
$$
\lim_{(x,y) \to (x_{0},y_{0})}f(x,y)=L \iff  \forall \varepsilon>0: \exists \delta>0 \;/\; 0<\lVert(x,y)-(x_{0},y_{0})\rVert<\delta \implies \left|f(x,y)-L\right|<\varepsilon
$$
:::

Volvamos un toque a análisis I. Cuando estudiabamos límites y queríamos saber si existía o no el límite de la función $y=f(x)$ cuando $x$ tiende a $x_{0}$, lo que hacíamos era calcular el límite por los dos únicos caminos que habían para llegar a ese punto $x_{0}$: por la izquierda y por la derecha. Si el límite por izquierda era igual al límite por derecha, entonces podíamos decir que el límite de la función existía en ese punto. 

Para las funciones de dos variables podemos decir lo mismo. Si queremos calcular el límite de $z=f(x,y)$ cuando un punto $P(x,y)$ tiende a $P_{0}(x_{0},y_{0})$, y podemos demostrar que el límite acercándonos por cualquier camino a $P_{0}$ es $L$, entonces podemos decir que ese límite existe. El problema está en que, como ahora tenemos dos variables, los caminos por los que nos podemos acercar a $P_{0}$ son infinitos, y es imposible calcular el límite de todos esos caminos para ver si nos dan igual.

Una opción sería calcular el límite por definición, pero eso es muy complicado así que lo descartamos.

Lo primero que conviene hacer siempre que nos den un límite es fijarnos si al reemplazar $(x,y)$ por $(x_{0},y_{0})$ podemos llegar a un resultado (igual que como hacíamos en análisis I). Si al reemplazar obtenemos un número, quiere decir que el límite existe y es ese número. Si llegamos a una indeterminación vamos a tener que arreglarnosla.

::: {.callout-tip title=Ejemplos}
- Calcular el límite cuando $(x,y)$ tiene a $(3,1)$ de la función $f(x,y)=xy-y^2$

  Reemplazamos $(x,y)$ en $f(x,y)$ y resolvemos
  $$
    \lim_{(x,y) \to (3,1)}\left(xy-y^2\right)=3\cdot 1 - 1^2 = 2
  $$

  El límite existe y es $L=2$.

- Calcular el límite cuando $(x,y) \to (0,0)$ de $f(x,y)=\frac{\sin^{}(3xy)}{x}$

  Primero reemplazamos y vemos si obtenemos un número
  $$
    \lim_{(x,y) \to (0,0)}\frac{\sin^{}(3xy)}{x}=\frac{3\cdot 0\cdot 0}{0}=\frac{0}{0}
  $$

  Como llegamos a una indeterminación, primero nos fijamos si la podemos salvar. La lógica es la misma que cuando trabajabamos con funciones escalares.
  $$
  \lim_{(x,y) \to (0,0)}\frac{\sin^{}(3xy)}{x}=\lim_{(x,y) \to (0,0)}\frac{3y\sin^{}(3xy)}{3xy}=\left(\lim_{(x,y) \to (0,0)}3y\right)\cdot \left(\lim_{(x,y) \to (0,0)}\frac{\sin^{}(3xy)}{3xy}\right)=0\cdot 1=0
  $$

  Como pudimos salvar la indeterminación, el límite existe y es igual a $L=0$.
:::

Si resulta que cuando reemplazamos $(x,y)$ llegamos a una indeterminación que no se puede salvar, la única opción que nos queda para saber si existe el límite es calcularlo por definición. Pero como dijimos, eso es muy complicado así que lo descartamos. 

No vamos a poder saber si existe el límite en estos casos, pero lo que sí podemos demostrar es que **no** existe. Si somos capaces de demostrar que acercándonos por dos caminos distintos al punto $P_{0}$, el límite no es igual, entonces queda demostrado que el límite en ese punto **no existe**. Vamos a ver dos formas de hacer esto: usando **límites iterados** y **límites radiales**.

OJO IGUAL, si no podemos encontrar esos dos caminos que nos den distintos límites, no quiere decir que el límite existe ya que hay infinitos caminos y no podemos estar 100% seguros de que uno no va a dar distinto.

## Límites iterados
Podemos calcular los límites de una función siguiendo trayectorias particulares, denominadas **Trayectorias escalonadas**. Estas trayectorias están constituidas por rectas paralelas a los ejes cartesianos y el método consiste en calcular los límites en un punto $P_{0}$, partiendo de $P$ y pasando una vez por $P_{1}$; después hacemos lo mismo, pero esta vez pasando por $P_{2}$. De esta manera, podemos comparar los resultados y fijarnos: si los dos límites nos dieron distinto, quiere decir que el límite de esa fnción en el punto $P_{0}$ no existe.

OJO! Si nos dan igual ya dijimos que no quiere decir que existe el límite. Simplemente significa que esas trayectorias nos dan el mismo resultado, pero existen infinitas mas que pueden dar distinto.

```{python}
#| label: fig-limites-iterados
#| fig-cap: Límites iterados (adapatado de @am2monllor [p. 17])

import matplotlib.pyplot as plt
from mpl_toolkits.axisartist.axislines import AxesZero

# Esto me lo copié de https://matplotlib.org/stable/gallery/axisartist/demo_axisline_style.html#sphx-glr-gallery-axisartist-demo-axisline-style-py
fig = plt.figure()
ax = fig.add_subplot(axes_class=AxesZero)

for direction in ["xzero", "yzero"]:
    # adds arrows at the ends of each axis
    ax.axis[direction].set_axisline_style("-|>")

    # adds X and Y-axis from the origin
    ax.axis[direction].set_visible(True)

for direction in ["left", "right", "bottom", "top"]:
    # hides borders
    ax.axis[direction].set_visible(False)

# Agrego lineas
label_p1 = "Camino por $P_{1}$: $\\lim_{y \\to y_{0}}\\left[\\lim_{x \\to x_{0}}f(x,y)\\right]$"
label_p2 = "Camino por $P_{2}$: $\\lim_{x \\to x_{0}}\\left[\\lim_{y \\to y_{0}}f(x,y)\\right]$"
camino_p1, = ax.plot([1, 4, 4], [1, 1, 4],  color="green", label=label_p1)
camino_p2, = ax.plot([1, 1, 4], [1, 4, 4],  color="red", label=label_p2)
ax.plot([1, 1], [0, 1], linestyle="--", color="gray")
ax.plot([4, 4], [0, 1], linestyle="--", color="gray")
ax.plot([0, 1], [1, 1], linestyle="--", color="gray")
ax.plot([0, 1], [4, 4], linestyle="--", color="gray")

# Agrego los puntos
ax.plot(1, 1, "o", color="blue")
ax.plot(4, 1, "o", color="blue")
ax.plot(1, 4, "o", color="blue")
ax.plot(4, 4, "o", color="blue")

# Agrego las etiquetas de los puntos
ax.text(1, 1, "$P$" , fontsize=12, ha="right", va="bottom")
ax.text(4, 1, "$P_{1}$", fontsize=12, ha="left", va="bottom")
ax.text(1, 4, "$P_{2}$", fontsize=12, ha="right", va="bottom")
ax.text(4, 4, "$P_{0}$", fontsize=12, ha="left", va="bottom")

# Límites de los ejes
ax.set_xlim(-1, 5)
ax.set_ylim(-1, 5)

# Labels de los ejes
ax.set_xticks([])
ax.set_yticks([])
ax.text(-0.2, 5, "$y$", fontsize=12)
ax.text(-0.2, 1, "$y$", fontsize=12)
ax.text(-0.2, 4, "$y_{0}$", fontsize=12)
ax.text(5, -0.3, "$x$", fontsize=12)
ax.text(1, -0.3, "$x$", fontsize=12)
ax.text(4, -0.3, "$x_{0}$", fontsize=12)

# Agrego leyendas
fig.legend(loc="upper right", fontsize=12)

# Mostrar el gráfico
plt.show()
```

::: {.callout-tip title=Ejemplo}
Dada $z=\frac{2x^2+y^3}{3x^2 - y^3}$, calcular el límite en el punto $P_{0}(0,0)$:
$$
  \lim_{(x,y) \to (0,0)}\frac{2x^2 + y^3}{3x^2 - y^3}
$$

Lo primero que hacemos es reemplazar $(x,y)$ por $(0,0)$ en la función. En este caso vamos a llegar a una indeterminación que no podemos salvar, así que podemos calcular los límites iterados para fijarnos si las dos trayectorias nos dan distintos valores de límites.
$$
\begin{aligned}
  \lim_{y \to 0}\left[\lim_{x \to 0}\frac{2x^2 + y^3}{3x^2 - y^3}\right] &= \lim_{y \to 0}\left[\frac{0+y^3}{0-y^3}\right] = \lim_{y \to 0} (-1) = -1\\
  \lim_{x \to 0}\left[\lim_{y \to 0}\frac{2x^2 + y^3}{3x^2 - y^3}\right] &= \lim_{x \to 0}\left[\frac{2x^2 + 0}{3x^2 - 0}\right] = \lim_{x \to 0}\left(\frac{2}{3}\right) = \frac{2}{3}
\end{aligned}
$$

Vemos que las dos trayectorias nos dieron distintos resultados, así que podemos afirmar que el límite de $f(x,y)$ en el punto $P_{0}(0,0)$ no existe.
:::

## Límites radiales
Otra estrategia que podemos tomar es calcular los límites radiales. Esta estrategia consiste en calcular el límite siguiendo las trayectorias del haz de rectas que pasan por el punto $P_{0}(x_{0},y_{0})$. De esta manera, todas las rectas que pasan por el punto $P_{0}$ las podemos escribir de la forma $r:(y-y_{0}) = m(x-x_{0})$.

```{python}
#| label: fig-limites-radiales
#| fig-cap: Límites radiales (adaptado de @am2monllor [p. 18])

# Esto me lo copié de https://matplotlib.org/stable/gallery/axisartist/demo_axisline_style.html#sphx-glr-gallery-axisartist-demo-axisline-style-py
fig = plt.figure()
ax = fig.add_subplot(axes_class=AxesZero)

for direction in ["xzero", "yzero"]:
    # adds arrows at the ends of each axis
    ax.axis[direction].set_axisline_style("-|>")

    # adds X and Y-axis from the origin
    ax.axis[direction].set_visible(True)

for direction in ["left", "right", "bottom", "top"]:
    # hides borders
    ax.axis[direction].set_visible(False)

# Dibujo las rectas que pasan por el punto P0
x0, y0 = 2, 2
for angulo in np.linspace(0, 2*np.pi, 10, endpoint=False) + np.pi/24:
  x_end = x0 + np.cos(angulo)
  y_end = y0 + np.sin(angulo)
  ax.plot([x_end, x0], [y_end, y0], color="black", linewidth=1)

# Dibujo las lineas punteadas
ax.plot([2, 2], [0, 2], linestyle="--", color="gray")
ax.plot([0, 2], [2, 2], linestyle="--", color="gray")

# Dibujo el punto P0
ax.plot(x0, y0, "o", color="blue")

# Límites de los ejes
ax.set_xlim(-0.5, 4)
ax.set_ylim(-0.5, 4)

# Labels de los ejes
ax.set_xticks([])
ax.set_yticks([])
ax.text(-0.2, 4, "$y$", fontsize=12)
ax.text(-0.2, 2, "$y_{0}$", fontsize=12)
ax.text(4, -0.3, "$x$", fontsize=12)
ax.text(2, -0.3, "$x_{0}$", fontsize=12)

plt.show()
```

Con este método, si $L$ queda en función de $m$ significa que va a tener un límite distinto para cada trayectoria, osea que no existe el límite en ese punto.

::: {.callout-tip title=Ejemplo}
Dada $z=\frac{2xy}{3x^2-y^2}$, calcular el límite de $z$ en el punto $P_{0}(0,0)$.
$$
  \lim_{(x,y) \to (0,0)}\frac{2xy}{3x^2 - y^2}
$$

De nuevo, lo primero que hacemos es reemplazar $(x,y)$ en la función por $(0,0)$. En este caso nos queda una indeterminación así que vamos a calcular los límites radiales para intentar demostrar que no existe el límite.

La idea de usar los límites radiales es que podemos expresar las infinitas rectas con dirección radial que pasan por el punto $P_{0}$ de la forma $r:y-y_{0}=m(x-x_{0})$. En este caso, nuestro punto es $P_{0}(0,0)$ así que la ecuación de $r$ es $y-0=m(x-0)$, que es lo mismo que $y=mx$.

Y ahora, tenemos una expresión de $y$ en función de $x$, así que podemos reemplazar $y$ en la función del límite y escribirlo de la siguiente forma.
$$
  \lim_{(x,y) \to (0,0)}\frac{2xy}{3x^2 - y^2} = \lim_{x \to 0}\frac{2x(mx)}{3x^2-(mx)^2}
$$

Nos quedó un límite que depende solo de $x$
$$
  \lim_{x \to 0}\frac{2xmx}{3x^2-(mx)^2}=\lim_{x \to 0}\frac{2x^2m}{x^2(3-m^2)}=\frac{2m}{3-m^2}
$$

El resultado de límite nos quedó en función de $m$, así que podemos afirmar que no existe el límite para esa función en el punto $P_{0}(0,0)$
:::

Veamos un último ejemplo

::: {.callout-tip title=Ejemplo}
Dada $z=\frac{2x^2y}{x^4+3y^2}$, calcular el límite de la función en el punto $P_{0}(0,0)$
$$
  \lim_{(x,y) \to (0,0)}\frac{2x^2y}{x^4+3y^2}
$$

Si reemplazamos vamos a tener una indeterminación, así que veamos qué pasa si calculamos los límites iterados
$$
\begin{aligned}
  \lim_{y \to 0}\left[\lim_{x \to 0}\frac{2x^2y}{x^4+3y^2}\right] &= 0\\
  \lim_{x \to 0}\left[\lim_{y \to 0}\frac{2x^2y}{x^4+3y^2}\right] &= 0
\end{aligned}
$$

Los dos límites nos dieron igual, así que el método no nos sirve para demostrar que el límite no existe. 

Recordemos que esto no quiere decir que existe el límite y que es $L=0$, porque hay infinitos caminos para llegar a $P_{0}$ y alguno puede dar distinto.

Calculemos los límites radiales entonces.

Como el punto es el $(0,0)$, la ecuación de $r$ es $y=mx$, así que reemplazamos $y$ en la ecuación.
$$
  \lim_{x \to 0}\frac{2x^2(mx)}{x^4+(mx)^2} = \lim_{x \to 0}\frac{x^2(2mx)}{x^2(x^2+3m^2} = \lim_{x \to 0}\frac{2mx}{x^2+3m^2}=0
$$

Este límite también nos volvió a dar cero, pero de vuelta, esto no significa que el límite de la función es $L=0$. Simplemente este método no sirve para demostrar la no existencia del límite. Si llegamos a este punto en realidad no hay mucho que podamos hacer ya que las posibilidades son infinitas, pero a modo de demostración, vamos a ver que si nos acercamos al punto $P_{0}$ con una parábola, el límite nos va a dar distinto así que vamos a poder afirmar que el límite no existe. Porque todas las trayectorias deben dar el mismo valor del límite, con que exista una (en este caso la parábola) que nos de distinto, ya es suficiente para afirmar la no existencia.

Para acercarnos a $P_{0}$ por una parábola decimos que $y=x^2$, y reemplazamos en la ecuación del límite.
$$
  \lim_{x \to 0}\frac{2x^2(x^2)}{x^4+(x^2)^2} = \lim_{x \to 0}\frac{2x^4}{x^4+3x^4} = \frac{2}{4} = \frac{1}{2}
$$

Ahora podemos ver que el límite nos dió distinto en una de las trayectorias, así que dicho límite no existe.
:::

# Continuidad
Es lo mismo que en análisis I. 

::: {.callout-note title=Definición}
Sea la función $z=f(x,y)$ y $P_{0}(x_{0},y_{0})$, se dice que $z$ es continua en $P_{0}$ si:
$$
  \lim_{(x,y) \to (x_{0},y_{0})}f(x,y)=f(x_{0},y_{0})
$$

Para que se cumpla esto se tienen que cumplir tres condiciones básicas:

1. Que el límite exista para $P(x,y) \to P_{0}(x_{0},y_{0})$

2. Que la función esté definida en $P_{0}(x_{0},y_{0})$

3. Que el límite de la función sea igual al valor de la función en $P_{0}(x_{0},y_{0})$
:::

Si la igualdad no se cumple en $P_{0}$ quiere decir que este es un **punto de discontinuidad**.

Si no existe el límite en ese punto, la discontinuidad es **esencial**.

Si existe el límite, pero la función no es continua, la discontinuidad es **evitable**. Lo que se hace es redefinir la función para que sea continua.

# Derivadas parciales
Dada una función $z=f(x,y)$ de dos variables independientes que describe a una superficie $S$, y dado un plano vertical $\pi:y=y_{0}$, la intersección de la superficie $S$ con el plano $\pi$ describe una curva que tiene la forma de $z=f(x,y_{0})$ (@fig-derivada-parcial) Si nos movemos a través del plano $\pi$, la variable $y$ se mantiene constante por lo que podemos considerar que la única variable de la función es $x$. Entonces, ahora podemos derivar la función como si fuese una función de una única variable $x$. Estaríamos entonces calculando la **derivada parcial de $\mathbf{f(x,y)}$ con respecto a $\mathbf{x}$**, que se expresa así:
$$
\frac{\partial f(x,y)}{\partial x} = \lim_{\Delta x \to 0}\frac{\Delta xf(x,y)}{\Delta x} = \lim_{\Delta x \to 0}\frac{f(x + \Delta x, y) - f(x,y)}{\Delta x}
$$

Otras formas de escribir la derivada parcial son las siguientes:
$$
  \frac{\partial f(x,y)}{\partial x} = \frac{\partial z}{\partial x} = \frac{\partial f}{\partial x} = z^{\prime}_{x} = f_{x}(x,y)
$$

La que mas le gusta a Moni es la ultima $f_{x}(x,y)$.

Lo mismo podemos hacer con la variable $y$ ahora. Mantenemos a $x$ constante y derivamos para obtener la **derivada parcial respecto de $\mathbf{y}$.**
$$
  \frac{\partial f(x,y)}{\partial y} = \lim_{\Delta y \to 0}\frac{\Delta yf(x,y)}{\Delta y} = \lim_{\Delta y \to 0}\frac{f(x, y + \Delta y) - f(x,y)}{\Delta y}
$$

Para calcular estas derivadas hacemos lo mismo que veníamos siempre, solo que ahora hay que tener en cuenta que si estamos haciendo la derivada parcial respecto de $x$, la variable $y$ es una constante y la tenemos que tratar como tal.

En los ejemplos que siguen voy a tratar de usar todas las notaciones distintas que existen de las derivadas parciales solo para aclarar que todas significan lo mismo. Siempre está bueno conocer todas las formas que hay de expresarlas porque cada autor usa la que mas le gusta, y mas adelante algunas definiciones usan una expresión u otra, pero todas significan lo mismo.

::: {.callout-tip title=Ejemplo}
Calcular las derivadas parciales de la función $z=y^3\cos^{}(x)$.

- Calculemos primero la derivada parcial respecto de $x$. Tenemos que considerar a $y$ como una constante.
  $$
    f_{x}(x,y) = -y^3\sin^{}(x)
  $$

- Ahora calculemos la derivada parcial respecto de $y$. Consideramos que $x$ es una constante ahora.
  $$
    \frac{\partial f(x,y)}{\partial y} = 3y^2\cos^{}(x)
  $$
:::

::: {.callout-tip title=Ejemplo}
Calcular las derivadas parciales de la función $z=3x^2y-y^2$ en el punto $P(1,2)$.

- Calculemos ahora primero la derivada parcial respecto de $y$.
  $$
    \frac{\partial z}{\partial y} = 3x^2 - 2y
  $$

  Como nos piden calcular la derivada en el punto $P(1,2)$, reemplazamos $(x,y)$ por $(1,2)$ en la ecuación de la derivada
  $$
    f_{y}(1,2) = 3\cdot 1^2 - 2\cdot 2 = -1
  $$

- Ahora calculemos la derivada parcial respecto de $x$.
  $$
    z_{x} = 6xy
  $$

  Y nos piden calcularla en el punto $P(1,2)$ así que reemplazamos
  $$
    \frac{\partial f(1,2)}{\partial x}=6\cdot 1\cdot 2 = 12
  $$
:::

## Interpretación geométrica de las derivadas parciales
Consideremos a la función $z=4-x^2-2y^2$ y busquemos sus derivadas parciales en el punto $P_{0}(1,1)$.
$$
\begin{aligned}
  \frac{\partial f(x,y)}{\partial x} = -2x && \frac{\partial f(1,1)}{\partial x} = -2\\
  \frac{\partial f(x,y)}{\partial y} = -4y && \frac{\partial f(1,1)}{\partial y} = -4
\end{aligned}
$$

Si miramos la @fig-derivada-parcial, podemos ver que cuando hacemos la derivada parcial respecto de $x$, nos estamos moviendo sobre el plano $y=1$, y la derivada parcial es la pendiente de la recta tangente a la curva generada por la intersección de la función $z$ con ese plano $y=1$.

Lo mismo podemos ver cuando hacemos la derivada parcial respecto de $y$, solo que ahora nos movemos sobre el plano $x=1$ y la derivada parcial es la pendiente de la recta tangente a la curva generada por la intersección de la función $z$ con ese plano $x=1$.

```{python}
#| label: fig-derivada-parcial
#| fig-cap: Interpretación geométrica de la derivada parcial (adaptado de @stewart2 [p. 915])

x = np.linspace(0, 2, 20)
y = np.linspace(0, np.sqrt(2), 20)
x, y = np.meshgrid(x, y)
z = 4 - x**2 - 2*y**2

fig = go.Figure()

# Superficie
fig.add_trace(go.Surface(x=x, y=y, z=z, colorscale="Viridis", opacity=0.6, showscale=False))

# Plano derivada parcial y
y = np.linspace(0, 2, 20)
z = np.linspace(0, 4, 20)
y, z = np.meshgrid(y, z)
x = np.ones_like(y)
fig.add_trace(go.Surface(x=x, y=y, z=z, colorscale="Pinkyl", opacity=0.8, showscale=False, visible=False))

# Intersección Superficie con Plano derivada parcial y
x = 1
y = np.linspace(0, np.sqrt(2), 20)
z = 4 - x**2 - 2*y**2
x_vals = np.full_like(y, x)
fig.add_trace(go.Scatter3d(x=x_vals, y=y, z=z, mode="lines", line=dict(color="red"), visible=False, name="Curva intersección"))

# Recta derivada parcial en y
x0, y0 = 1, 1
z0 = 4 - x0**2 - 2*y0**2
df_dy = -4*y0
y = np.linspace(0, 2, 20)
x = np.full_like(y, 1)
z = z0 + df_dy*(y - y0)
fig.add_trace(go.Scatter3d(
  x=x, y=y, z=z,
  mode="lines",
  line=dict(color="cyan"),
  name="Derivada parcial respecto de y",
  visible=False,
))


# Plano derivada parcial x
x = np.linspace(0, 2, 20)
z = np.linspace(0, 4, 20)
y, z = np.meshgrid(x, z)
y = np.ones_like(x)
fig.add_trace(go.Surface(x=x, y=y, z=z, colorscale="Pinkyl", opacity=0.8, showscale=False, visible=True))

# Intersección Superficie con Plano derivada parcial x
y = 1
x = np.linspace(0, np.sqrt(2), 20)
z = 4 - x**2 - 2*y**2
y_vals = np.full_like(x, y)
fig.add_trace(go.Scatter3d(x=x, y=y_vals, z=z, mode="lines", line=dict(color="red"), visible=True, name="Curva intersección"))

# Recta derivada parcial en x
x0, y0 = 1, 1
z0 = 4 - x0**2 - 2*y0**2
df_dx = -2*x0
x = np.linspace(0, 2, 20)
y = np.full_like(x, 1)
z = z0 + df_dx*(x - x0)
fig.add_trace(go.Scatter3d(
  x=x, y=y, z=z,
  mode="lines",
  line=dict(color="cyan"),
  name="Derivada parcial respecto de x",
  visible=True,
))


# Punto (1,1)
x = 1
y = 1
z = 1
fig.add_trace(go.Scatter3d(
    x=[x], y=[y], z=[z],
    mode='markers+text',
    marker=dict(size=4, color='cyan'),
    text=["P"],
    textposition='middle right',
    showlegend=False,
))

# Ajusto los límites de los ejes
fig.update_layout(
  updatemenus=[dict(
      type="buttons",
      direction="right",
      x=0.5, xanchor="center",
      y=1, yanchor="top",
      buttons=list([
        dict(label="Derivada parcial en x",
             method="update",
             args=[{"visible": [True, False, False, False, True, True, True]},
             {"title": "DPy"}]),
        dict(label="Derivada parcial en y",
             method="update",
             args=[{"visible": [True, True, True, True, False, False, False]},
             {"title": "DPx"}]),
      ]),
  )],
  scene=dict(
    xaxis=dict(range=[0, 3]),
    yaxis=dict(range=[0, 2]),
    zaxis=dict(range=[0, 5]),
    aspectmode="cube",
  )
)
```

## Derivabilidad de una función 
Una función de varias variables es derivable en un punto si es continua en ese punto.

## Derivadas parciales sucesivas
Al igual que con las derivadas normales, una derivada parcial la podemos derivar cuantas veces queramos obteniendo derivadas parciales segundas, terceras, etc., con respecto a cada una de las variables consideradas.

Por ejemplo, podemos tener una función $z=f(x,y)$ y su derivada primera respecto de $x$ es $\frac{\partial z}{\partial x}$. Y a esta función derivada, la podemos volver a derivar respecto de $x$ pero también respecto de $y$ si quisieramos. Si la derivamos respecto de $x$ obtenemos $\frac{\partial^2 z}{\partial x^2}$, y si la derivamos respecto de $y$ nos queda $\frac{\partial^2 z}{\partial y \partial x}$. Lo mismo podemos hacer con la derivada parcial respecto de $y$. Pero todo esto se ve mas claro con un ejemplo.

::: {.callout-tip title=Ejemplo}
Calcular las derivadas de segundo orden de la función $z=x^4\sin^{}(5y)$.

- Calculemos primero las derivadas de primer orden
  $$
  \begin{aligned}
    \frac{\partial z}{\partial x} &= 4x^3\sin^{}(5y)\\
    \frac{\partial z}{\partial y} &= 5x^4\cos^{}(5y)
  \end{aligned}
  $$

  Ambas derivadas pueden ser derivadas nuevamente para obtener las derivadas parciales de segundo orden:
  $$
  \begin{aligned}
    \frac{\partial^2 z}{\partial x^2} &= \frac{\partial \left[4x^3\sin^{}(5y)\right]}{\partial x} = 12x^2\sin^{}(5y)\\
    \frac{\partial^2 z}{\partial y \partial x} &= \frac{\partial \left[4x^3\sin^{}(5y)\right]}{\partial y} = 20x^3\cos^{}(5y)\\
    \frac{\partial^2 z}{\partial y^2} &= \frac{\partial \left[5x^4\cos^{}(5y)\right]}{\partial y} = -25x^4\sin^{}(5y)\\
    \frac{\partial^2 z}{\partial x \partial y} &= \frac{\partial \left[5x^4\cos^{}(5y)\right]}{\partial x} = 20x^3\cos^{}(5y)\\
  \end{aligned}
  $$
:::

Podríamos seguir derivando las derivadas de segundo orden para obtener las de tercer orden, y luego podríamos derivar esas de tercer orden y así sucesivamente. Pero por suerte el ejercicio nos pide solo las de segundo orden.

En el ejemplo podemos ver que las derivadas parciales sucesivas no son todas distintas. Las derivadas parciales $\frac{\partial^2 z}{\partial x \partial y}$ y $\frac{\partial^2 z}{\partial y \partial x}$ nos dieron el mismo resultado. Esto no fue ninguna coincidencia, hay un teorema que dice lo siguiente:

*"Si las derivadas sucesivas a calcular son continuas, el orden de derivación no altera la derivada, siempre que la cantidad de veces que se derive respecto a cada variable sea la misma."*

En otras palabras, si derivamos primero respecto a $x$ y luego respecto a $y$ (o en el orden inverso), siempre que todas las derivadas sean continuas y hayamos derivado tantas veces respecto a $x$ como respecto a $y$, el resultado será el mismo.

## Expresiones matriciales de las derivadas
Suele ser útil expresar las derivadas de las funciones en su forma matricial. Así, dada una función $f:\mathbb{R}^{n} \to \mathbb{R}^{}$ podemos expresar las derivadas de $f$ con una matriz fila. Esta matriz se denota $Df$:
$$
  Df(x_{1}, \dots , x_{n}) = \begin{bmatrix}
    \frac{\partial f}{\partial x_{1}} & \dots & \frac{\partial f}{\partial x_{n}}
  \end{bmatrix}
$$

::: {.callout-tip title=Ejemplo}
Armar la expresión matricial de las derivadas de primer orden de la función $z=x^2 + 2xy^3 - \cos^{}(y)$.

- Como tenemos dos variables independientes, nuestra matriz va a tener dos columnas. Cada columna es la derivada respecto de cada variable
  $$
  \begin{aligned}
    f_{x}(x,y) = 2x + 2y^3 && f_{y}(x,y) = 6xy^2 + \sin^{}(y)
  \end{aligned}
  $$
  Así que la matriz derivada es la siguiente
  $$
    Df(x,y)=\begin{bmatrix}
      2x + 2y^3 & 6xy^2 + \sin^{}(y)
    \end{bmatrix}
  $$

:::

Para el caso general en que $f:\mathbb{R}^{n} \to \mathbb{R}^{m}$, la matriz derivada va a tener $m$ filas y $n$ columnas, $Df \in \mathbb{R}^{m\times n}$. Antes de ver esta matriz estaría bueno volver a leer la parte de campos vectoriales en la @sec-funciones para entender bien la notación de la matriz que sigue.
$$
  Df(\vec{x})=\begin{bmatrix}
    \frac{\partial f_{1}}{\partial x_{1}} & \dots & \frac{\partial f_{1}}{\partial x_{n}}\\
    \vdots & \ddots & \vdots \\
    \frac{\partial f_{m}}{\partial x_{1}} & \dots & \frac{\partial f_{m}}{\partial x_{n}}
  \end{bmatrix}
$$

::: {.callout-tip title=Ejemplo}
Obtener la matriz derivada del campo vectorial $f(x,y)=(2x^2 + e^{3x - y}, sin(3x + y^2))$.

- Nuestra matriz va a ser de dos filas por dos columnas porque la imagen son los vectores de dimensión 2 (filas) y el dominio son vectores de dimensión 2 también (columnas).

  Para armar esta matriz, tenemos que derivar cada componente del vector imagen respecto a cada una de las variables. A las componentes del vector las llamamos $f_{i}(x,y)$, donde $1\leq i\leq m$. En este caso tenemos que $f_{1}(x,y)=2x^2+e^{3x-y}$, y $f_{2}(x,y)=\sin^{}(3x+y^2)$.

  La matríz entonces sería así
  $$
    Df(x,y) = \begin{bmatrix}
      \frac{\partial f_{1}}{\partial x} & \frac{\partial f_{1}}{\partial y}\\[0.3cm]
      \frac{\partial f_{2}}{\partial x} & \frac{\partial f_{2}}{\partial y}
    \end{bmatrix}
  $$

  Busquemos entonces las derivadas parciales
  $$
  \begin{aligned}
    \frac{\partial f_{1}}{\partial x} &= 4x + 3e^{3x-y} & \frac{\partial f_{1}}{\partial y} =& -e^{3x-y}\\
    \frac{\partial f_{2}}{\partial x} &= 3\cos^{}(3x+y^2) & \frac{\partial f_{2}}{\partial y} =& 2y\cos^{}(3x+y^2)
  \end{aligned}
  $$

  Entonces la matriz derivada nos queda así
  $$
    Df(x,y)=\begin{bmatrix}
      4x + 3e^{3x-y} && -e^{3x-y}\\
      3\cos^{}(3x+y^2) && 2y\cos^{}(3x+y^2)
    \end{bmatrix}
  $$
:::

Cuando estemos trabajando con funciones de $\mathbb{R}^{2} \to \mathbb{R}^{}$ (que al final van a ser las funciones con las que mas vamos a trabajar este año), podemos definir una matriz derivada para las segundas derivdas de la función. Esta matriz lleva el nombre de **matriz Hessiana**, se denota como $Hf$ y va a ser muy útil durante la cursada.
$$
  Hf(x,y)=\begin{bmatrix}
    f_{xx} & f_{xy} \\
    f_{yx} & f_{yy}
  \end{bmatrix}
$$

::: {.callout-tip title=Ejemplo}
Obtener la matriz derivada de segundo orden de la función $z=e^{3x+y}-x^2y+2y$.

- Primero buscamos las primeras derivadas parciales para poder calcular las segundas derivadas.
  $$
  \begin{aligned}
    f_{x}(x,y) = 3e^{3x+y}-2xy && f_{y}(x,y)=e^{3x+y}-x^2+2
  \end{aligned}
  $$

- Ahora calculamos las 4 segundas derivadas
  $$
  \begin{aligned}
    f_{xx}(x, y) &= 9e^{3x+y}-2y\\
    f_{xy}(x, y) &= 3e^{3x+y}-2x\\
    f_{yx}(x,y) &= 3e^{3x+y}-2x\\
    f_{yy}(x,y) &= e^{3x+y}
  \end{aligned}
  $$

- Y ya tenemos todo para armar la matriz
$$
  Hf(x,y)=\begin{bmatrix}
    9e^{3x+y}-2y & 3e^{3x+y}-2x\\
    3e^{3x+y}-2x & e^{3x+y}
  \end{bmatrix}
$$
:::

## Diferencial
Acá viene un tema importante. Creo que lo mejor para entenderlo bien del todo es volver a análisis I y trabajar con funciones de $\mathbb{R}^{}  \to  \mathbb{R}^{}$. Una vez que entendamos bien qué es el diferencial ahí, vamos a pasar a estudiarlo en funciones de $\mathbb{R}^{n} \to \mathbb{R}^{m}$.

La notación diferencial en realidad la venimos viendo hace un montón pero nunca supimos de dónde venía ni qué significaba. La veíamos por ejemplo cuando estudiabamos derivadas, que podiamos expresarla como $\frac{dy}{dx}$, donde $y=f(x)$. también la veíamos en las integrales de la forma $\int_{}^{} f(x) \,dx$. Esto lo tomabamos que solo era una notación, pero en realidad no, $dx$ y $dy$ son dos variables que tiene la propiedad de que cuando su razón existe, esta es igual a la derivada.

::: {.callout-note title=Definición}
Diferencial en funciones escalares

Sea $y=f(x)$ una función derivable. La diferencial $dx$ es una variable independiente. La diferencial $dy$ es
$$
  dy = f^{\prime}(x)dx
$$
:::

Como $dx$ es una variable independiente, nosotros le podemos dar el valor que se nos cante. El valor de $dy$ por otro lado, depende tanto del valor que le demos a la variable $dx$ como del valor que le demos a la variable $x$.

Sé que esto no nos dijo nada todavía, pero sigamos estudiandolo para tratar de entender el diferencial.

### Interpretación geométrica del diferencial
En la siguiente figura podemos ver gráficamente a qué llamamos $dx$ y $dy$.

![Imagen sacada de @thomas1 [p. 42]. Interpretación geométrica del diferencial.](./imagenes/interp-geom-diferencial-1.png){#fig-interp-geom-diferencial}

En la @fig-interp-geom-diferencial podemos ver que $\Delta L$ es el cambio en $y$ de la recta tangente a la curva cuando $x$ cambia de $x=a$ a $x=a+dx$. Y en el gráfico dice que $\Delta L=f^{\prime}(a)dx$, que habíamos dicho en la definición anterior que eso era $dy$. Esta igualdad $\Delta L = dy$ la podemos comprobar de la siguiente manera:
$$
\begin{aligned}
  \Delta L &= L(a+dx) - L(a)\\
  \Delta L &= \underbrace{f(a) + f^{\prime}(a)\left[(a+dx)-a\right]}_{L(a+dx)} - \underbrace{f(a)}_{L(a)}\\
  \Delta L &= f^{\prime}(a)dx
\end{aligned}
$$

Entonces $\Delta L = dy$ representa la magnitud que se eleva o desciende la recta tangente cuando $x$ cambia en una cantidad $dx=\Delta x$.

Si $dx\neq 0$, entonces el cociente de la diferencial $dy$ entre la diferencial $dx$ es la pendiente de la recta $L$ que es tangente a la función, y "oh sorpresa", la pendiente de la recta tangente a una función es su derivada. Acabamos de llegar a que $f^{\prime}(x)=\frac{dy}{dx}$.

::: {.callout-tip title=Ejemplo}
Calcular el diferencial $dy$ de la ecuación $f(x)=3x^2-6$.

- Usamos la fórmula del diferencial que nos dice que $dy=f^{\prime}(x)dx$
$$
  f^{\prime}(x)=6x \text{, así que } dy=6xdx
$$
:::

### Estimacíon con diferenciales
::: {.callout-note}
Acá me mezclaba al principio así que vamos a hacer un par de aclaraciones.

- $dx=\Delta x$ es la distancia que nos movemos en el eje $x$.

- $\Delta y$ es lo que varía **la función** $f(x)$ si nos movemos una distancia $\Delta x=dx$ sobre el eje $x$. La variación $\Delta y$ se calcula como cualquier variación: punto final menos punto inicial
$$
\Delta y = f(a+\Delta x) - f(a)
$$

- $dy\neq \Delta y$. Lo digo en palabras: $dy$ **no es lo mismo que** $\Delta y$.

  $\Delta y$ es lo que varía **la función** cuando nos movemos una distancia $dx$.

  $dy$ es lo que varía **la recta tangente a la función** cuando nos movemos una distancia $dx$.

- Lo que sí podemos decir, y de hecho lo podemos ver en la @fig-interp-geom-diferencial, es que si $dx$ es muy chiquito, el valor de $dy$ es aproximadamente igual al de $\Delta y$. Pero siguen sin ser el mismo.
:::

Ahora sí, empecemos con las estimaciones. También se les puede decir aproximación.

Supongamos que conocemos el valor de una función derivable $y=f(x)$ en un punto $a$ y necesitamos estimar cuánto cambiará el valor si nos movemos una distancia $dx=\Delta x$. Es decir, necesitamos estimar cuánto cambiará el valor al calcular $f(a+dx)$. 

Si la distancia $dx$ es pequeña, podemos decir que $\Delta y$ es aproximadamente igual (solo aproximadamente) a $dy$.

Sabemos que $\Delta y=f(a+dx)-f(a)$, y si reordenamos la ecuación nos queda que $f(a+dx)=f(a)-\Delta y$. Ahora, recién dijimos que si $dx$ era muy chiquito podíamos decir que el valor de $\Delta y$ era aproximadamente igual al de $dy$ así que podemos decir lo siguiente:
$$
  f(a+dx) = f(a)+\Delta y  \implies f(a+dx)\approx f(a)+dy
$$

De esta manera, como ya conocemos la fórmula para calcular $dy$, podemos estimar el valor de $f(a+dx)$ cuando conocemos el valor de $f(a)$ y $dx$ es muy pequeño.

## Diferencial en funciones de varias variables
Ahora sí, ya estamos listos para estudiar el diferencial en funciones de varias variables.

Cuando trabajabamos recién con funciones escalares dijimos que el diferencial $dy$ (siendo $y$ la variable dependiente) era la variación de la recta tangente a la curva $y=f(x)$ en un punto $a$ cuando nos moviamos una distancia $dx$.

Ahora vamos a trabajar con campos escalares de $\mathbb{R}^{2} \to \mathbb{R}^{}$, de manera que vamos a tener 2 variables independientes (generalmente $x$ e $y$) y una variable dependiente $z$.

Como tenemos dos variables independientes, vamos a poder definir dos rectas tangentes (en vez de una sola) a una superficie (en vez de una curva) en un punto $P_{0}(x_{0},y_{0},f(x_{0},y_{0}))$.

Entonces, tenemos un punto de la superficie y dos rectas tangentes a dicha superficie, por lo que podemos armar la ecuación del plano que es tangente a la superficie en el punto $P_{0}$. Vamos a decir que, en una bola alrededor del punto $P_{0}$, este plano es una buena aproximación a la función $z=f(x,y)$ cuando el radio de la bola tiende a cero.

El **diferencial** de la función $z=f(x,y)$ va a ser la variación del plano tangente a la superficie en un punto $P_{0}(x_{0}, y_{0}, f(x_{0}, y_{0}))$ al movernos una distancia $dx=\Delta x$ en el eje $x$ y $dy=\Delta y$ en el eje $y$.

Podemos deducir la ecuación del diferencial de una función $z=f(x,y)$ utilizando la ecuación general del plano y teniendo en cuenta que estamos buscando un plano tangente a la superficie en un punto $P_{0}(x_{0},y_{0},z_{0})$.

La ecuación general de un plano que pasa por $P_{0}(x_{0},y_{0},z_{0})$ es
$$
  A(x-x_{0}) + B(y-y_{0}) + C(z-z_{0})=0
$$

Como nosotros queremos saber cuánto varía este plano en el eje $z$, podemos reordenar la ecuación de la siguiente forma
$$
\begin{aligned}
  -C(z-z_{0}) &= A(x-x_{0}) + B(y-y_{0})\\
  z-z_{0} &= \frac{A}{-C}(x-x_{0}) + \frac{B}{-C}(y-y_{0})
\end{aligned}
$$

Ahora podemos decir que $\frac{A}{-C}=a$ y que $\frac{B}{-C}=b$ para obtener
$$
  z-z_{0}=a(x-x_{0}) + b(y-y_{0})
$$

Bien, ya tenemos entonces la ecuación del plano tangente a la superficie, al que vamos a nombrar $\pi$. Esta ecuación representa lo que llamamos **diferencial total** de $z$, denotado como $dz$. Aunque $dz$ no es el cambio real $\Delta z=f(x+dx, y+dy)-f(x,y)$, se dice que **es una buena aproximación** cuando $dx$ y $dy$ son pequeños. En otras palabras, el plano tangente a la superficie representa una aproximación lineal al comportamiento de la función $z=f(x,y)$ en un entorno cercano al punto $P_{0}(x_{0},y_{0})$.

Cabe aclarar que para que una función sea diferenciable en un punto $P_{0}$, debe existir un plano tangente a la función en $P_{0}$. Esto quiere decir que la función debe ser continua en $P_{0}$ y no debe tener dobleces, esquinas o picos en la gráfica. En otras palabras, la gráfica de la función debe ser *suave*.

Podemos decir entonces que 
$$
  dz=a(x-x_{0}) + b(y-y_{0})
$$

Nos queda saber cuánto valen $a$ y $b$, así que sigamos analizando. ¿Qué datos conocemos del plano $\pi$? Sabemos que es tangente a la superficie $z=f(x,y)$ en el punto $P_{0}(x_{0}, y_{0})$. Esto quiere decir que la pendiente de este plano en el eje $x$ es la misma que la de la recta tangente a la curva generada por la intersección de la superficie con el plano $x=x_{0}$. Osea, que la pendiente de $\pi$ en el eje $x$ es $f_{x}(x_{0},y_{0})$. Lo mismo pasa con la pendiente en $y$ del plano, es igual a $f_{y}(x_{0},y_{0})$. Estos son los valores de $a$ y $b$, respectivamente.

La ecuación del diferencial de $z$ nos queda entonces así:
$$
  dz=f_{x}(x_{0},y_{0})(x-x_{0}) + f_{y}(x_{0},y_{0})(y-y_{0})
$$

y como $\Delta x = dx$ y $\Delta y = dy$, podemos decir
$$
  dz=f_{x}(x_{0},y_{0})dx + f_{y}(x_{0},y_{0})dy
$${#eq-diferencial-z}


```{python}
#| label: fig-visualizacion-diferencial
#| fig-cap: Visualización del plano tangente a $f(x,y)=4-x^2-2y^2$ en el punto $P_{0}(1,1)$.

x = np.linspace(0, 2, 20)
y = np.linspace(0, np.sqrt(2), 20)
x, y = np.meshgrid(x, y)
z = 4 - x**2 - 2*y**2

fig = go.Figure()

# Superficie
fig.add_trace(go.Surface(x=x, y=y, z=z, colorscale="Viridis", opacity=0.6, showscale=False))

# Plano tangente a la superficie en (1, 1, f(1, 1))
a = -2
b = -4
c = 7
x = np.linspace(0, 3, 20)
y = np.linspace(0, 2, 20)
x, y = np.meshgrid(x, y)
z = a*x + b*y + c
fig.add_trace(go.Surface( x=x, y=y, z=z, colorscale=[[0, "yellow"], [1, "plum"]], opacity=0.5, visible=True, showscale=False))


# Plano derivada parcial y
y = np.linspace(0, 2, 300)
z = np.linspace(0, 4, 300)
y, z = np.meshgrid(y, z)
x = np.ones_like(y)
# Mask es para que el plano quede contenido dentro de la superficie
mask = z <= 4 - 1**2 - 2*y**2
mask_x = np.where(mask, x, np.nan)
mask_y = np.where(mask, y, np.nan)
mask_z = np.where(mask, z, np.nan)
fig.add_trace(go.Surface(x=mask_x, y=mask_y, z=mask_z, colorscale=[[0, "paleturquoise"], [1, "paleturquoise"]], opacity=0.8, showscale=False, visible=False))

# Intersección Superficie con Plano derivada parcial y
x = 1
y = np.linspace(0, np.sqrt(2), 20)
z = 4 - x**2 - 2*y**2
x_vals = np.full_like(y, x)
fig.add_trace(go.Scatter3d(x=x_vals, y=y, z=z, mode="lines", line=dict(color="red"), visible=False, name="Curva intersección"))

# Recta derivada parcial en y
x0, y0 = 1, 1
z0 = 4 - x0**2 - 2*y0**2
df_dy = -4*y0
y = np.linspace(0, 2, 20)
x = np.full_like(y, 1)
z = z0 + df_dy*(y - y0)
fig.add_trace(go.Scatter3d(
  x=x, y=y, z=z,
  mode="lines",
  line=dict(color="cyan"),
  name="Derivada parcial respecto de y",
  visible=False,
))


# Plano derivada parcial x
x = np.linspace(0, 3, 300)
z = np.linspace(0, 4, 300)
y, z = np.meshgrid(x, z)
y = np.ones_like(x)
# Mask es para que el plano quede contenido dentro de la superficie
mask = z <= 4 - x**2 - 2*1**2
mask_x = np.where(mask, x, np.nan)
mask_y = np.where(mask, y, np.nan)
mask_z = np.where(mask, z, np.nan)
fig.add_trace(go.Surface(x=mask_x, y=mask_y, z=mask_z, colorscale=[[0, "paleturquoise"], [1, "paleturquoise"]], opacity=0.8, showscale=False, visible=True))

# Intersección Superficie con Plano derivada parcial x
y = 1
x = np.linspace(0, np.sqrt(2), 20)
z = 4 - x**2 - 2*y**2
y_vals = np.full_like(x, y)
fig.add_trace(go.Scatter3d(x=x, y=y_vals, z=z, mode="lines", line=dict(color="red"), visible=True, name="Curva intersección"))

# Recta derivada parcial en x
x0, y0 = 1, 1
z0 = 4 - x0**2 - 2*y0**2
df_dx = -2*x0
x = np.linspace(0, 2, 20)
y = np.full_like(x, 1)
z = z0 + df_dx*(x - x0)
fig.add_trace(go.Scatter3d(
  x=x, y=y, z=z,
  mode="lines",
  line=dict(color="cyan"),
  name="Derivada parcial respecto de x",
  visible=True,
))


# Punto (1,1)
x = 1
y = 1
z = 1
fig.add_trace(go.Scatter3d(
    x=[x], y=[y], z=[z],
    mode='markers+text',
    marker=dict(size=4, color='cyan'),
    text=["P0"],
    textposition='middle right',
    showlegend=False,
))

# Ajusto los límites de los ejes
fig.update_layout(
  updatemenus=[dict(
      type="buttons",
      direction="right",
      x=0.5, xanchor="center",
      y=1, yanchor="top",
      buttons=list([
        dict(label="Derivada parcial en x",
             method="update",
             args=[{"visible": [True, True, False, False, False, True, True, True]},
             {"title": "DPy"}]),
        dict(label="Derivada parcial en y",
             method="update",
             args=[{"visible": [True, True, True, True, True, False, False, False]},
             {"title": "DPx"}]),
      ]),
  )],
  scene=dict(
    xaxis=dict(range=[0, 3]),
    yaxis=dict(range=[0, 2]),
    zaxis=dict(range=[0, 5]),
    aspectmode="cube",
  )
)
```

La @fig-no-diferenciable muestra un ejemplo de una función $f(x,y)=x^{1/3}y^{1/3}$ que no es diferenciable en el punto $P_{0}(0,0)$ ya que la gráfica de la función no es *suave* en ese punto. Debido a esto, es imposible definir un plano tangente a la superficie en $P_{0}$.

```{python}
#| label: fig-no-diferenciable
#| fig-cap: La función $f(x,y)=x^{1/3}y^{1/3}$ no es diferenciable en $(0,0)$ (adaptado de @tromba [p. 122]).

x = np.linspace(-1, 3, 100)
y = np.linspace(-1, 3, 100)
x, y = np.meshgrid(x, y)
z = np.cbrt(x)*np.cbrt(y)   # Tengo que usar esto porque sino la raíz cúbica no funciona

fig = go.Figure()
fig.add_trace(go.Surface(x=x, y=y, z=z, colorscale="Viridis", opacity=0.7, showscale=False))

fig.update_layout(
  scene=dict(
    xaxis=dict(range=[-1, 3]),
    yaxis=dict(range=[-1, 3]),
    zaxis=dict(range=[0, 3]),
  )
)
```

::: {.callout-tip title=Ejemplo}
Aproximar el cambio en $z=\sqrt[]{4-x^2-y^2}$ cuando $(x,y)$ se desplaza del punto $(1,1)$ al punto $(1.01, 0.97)$. Comprobar esta aproximación con el cambio exacto en $z$.

El cambio de $z$ es $\Delta z$ y nos están pidiendo que lo aproximemos, así que tenemos que usar la @eq-diferencial-z
$$
  \Delta z \approx dz=f_{x}(x,y)dx+f_{y}(x,y)dy
$$
Necesitamos entonces calcular las derivadas parciales de la función, y determinar la distancia que nos movimos en cada eje.

- Calculemos primero las distancias $dx$ y $dy$ que es lo mas facil.
  
  Como en $x$ nos movimos desde 1 hasta 1.01, la distancia $dx$ es $dx=1.01-1=0.01$. Lo mismo hacemos para obtener $dy$, entonces $dy=0.97-1=-0.03$.

- Ahora calculemos las derivadas parciales
  $$
  \begin{aligned}
    f_{x}(x,y)=\frac{-x}{\left(4-x^2-y^2\right)^{1/2}} && f_{x}(1,1)=-\frac{1}{\sqrt[]{2}} \\
    f_{y}(x,y)=\frac{-y}{\left(4-x^2-y^2\right)^{1/2}} && f_{y}(1,1)=-\frac{1}{\sqrt[]{2}}
  \end{aligned}
  $$

- Y ahora solo queda reemplazar los valores obtenidos en la ecuación 
  $$
    dz=-\frac{1}{\sqrt[]{2}}(0.01)-\frac{1}{\sqrt[]{2}}(-0.03)\approx 0.0141
  $$

Entonces podemos decir que si desde el punto $(1,1)$ nos desplazamos al punto $(1.01,0.97)$, $\Delta z \approx 0.0141$.

- Calculemos ahora el valor real de $\Delta z$. Vimos la fórmula cuando vimos incrementos de una función (@eq-incremento-total-z).
  $$
  \begin{aligned}
    \Delta z &= f(1.01, 0.97)-f(1,1)\\
     &= \sqrt[]{4-(1.01)^2-(0.97)^2} - \sqrt[]{4-1^2-1^2} \approx 0.0137
  \end{aligned}
  $$
:::

## La regla de la cadena
La regla de la cadena funciona de manera similar a como lo hacía cuando trabajabamos con funciones escalares, solo que ahora al tener mas variables se agregan alguna cosas. La regla de la cadena conviene explicarla en dos casos separados y después presentar el caso general que aplica a cualquier función $f:\mathbb{R}^{n} \to \mathbb{R}^{m}$.

### Primero caso
Supongamos que $z=f(x,y)$ es una función derivable de $x$ e $y$, donde $x=g(t)$ e $y=h(t)$ son funciones derivables de $t$. Entonces decimos que $z$ es una función derivable de $t$ y se calcula como 
$$
  \frac{dz}{dt}=\frac{\partial f}{\partial x}\frac{dx}{dt} + \frac{\partial f}{\partial y}\frac{dy}{dt}
$$

Fijemonos que en este caso, la derivada de la función $z$ respecto de $t$ ya no es una derivada parcial ya que $t$ es la única variable de la función. Podemos reescribir $z$ en función de $t$ para que quede mas evidente de la siguiente manera
$$
  z=f(x(t),y(t))
$$

::: {.callout-tip title=Ejemplo}
Usar la regla de la cadena para obtener la derivada de $z=xy$ con respecto a $t$ a lo largo de la trayectoria $x=\cos^{}(t)$, $y=\sin^{}(t)$. ¿Cuál es el valor de la derivada en $t=\pi/2$?

Usamos la fórmula que vimos recién para obtener $\frac{\partial z}{\partial t}$ como sigue
$$
\begin{aligned}
  \frac{dz}{dt} &= \frac{\partial z}{\partial x}\frac{dx}{dt} + \frac{\partial z}{\partial y}\frac{dy}{dt}\\
   &= \frac{\partial (xy)}{\partial x}\frac{d(\cos^{}(t))}{t} + \frac{\partial (xy)}{\partial y}\frac{d(\sin^{}(t)}{t}\\
   &= (y)(-\sin^{}(t)) + (x)(\cos^{}(t))\\
   &= (\sin^{}(t))(-\sin^{}(t)) + (\cos^{}(t))(\cos^{}(t))\\
   &= -\sin^{2}(t) + \cos^{2}(t) \\
   &= \cos^{}(2t)
\end{aligned}
$$
:::

### Segundo caso
Supongamos ahora que $z=f(x,y)$ es una función derivable de $x$ e $y$, donde $x=g(s,t)$ e $y=h(s,t)$ son funciones derivables de $s$ y $t$. Entonces, las derivadas de $z$ respecto de $t$ y $s$ son
$$
\begin{aligned}
  \frac{\partial z}{\partial s}=\frac{\partial z}{\partial x}\frac{\partial x}{\partial s} + \frac{\partial z}{\partial y}\frac{\partial y}{\partial s} && \frac{\partial z}{\partial t}=\frac{\partial z}{\partial x}\frac{\partial x}{\partial t} + \frac{\partial z}{\partial y}\frac{\partial y}{\partial t}
\end{aligned}
$$

::: {.callout-tip title=Ejemplo}
Si $z=e^x\sin^{}(y)$, donde $x=st^2$ e $y=s^2t$, determinar $\frac{\partial z}{\partial s}$ y $\frac{\partial z}{\partial t}$.

$$
\begin{aligned}
  \frac{\partial z}{\partial s} &= \frac{\partial z}{\partial x}\frac{\partial x}{\partial s} + \frac{\partial z}{\partial y}\frac{\partial y}{\partial s}\\
   &= (e^x\sin^{}(y))(t^2) + (e^x\cos^{}(y))(2st)\\
   &= t^2e^{st^2}\sin^{}(s^2t)+2ste^{st^2}\cos^{}(s^2t)
\end{aligned}
$$
$$
\begin{aligned}
  \frac{\partial z}{\partial t} &= \frac{\partial z}{\partial x}\frac{\partial x}{\partial t} + \frac{\partial z}{\partial y}\frac{\partial y}{\partial t}\\
   &= (e^x\sin^{}(y))(2st) + (e^x\cos^{}(y))(s^2)\\
   &= 2ste^{st^2}\sin^{}(s^2t) + s^2e^{st^2}\cos^{}(s^2t)
\end{aligned}
$$
:::

### Versión general de la regla de la cadena
Supongamos que $u$ es una función derivable de las $n$ variables $x_{1},\dots ,x_{n}$ y que cada $x_{j}$ es una función derivable de las $m$ variables $t_{1}, \dots ,t_{m}$. Entonces, $u$ es una función de $t_{1},\dots ,t_{m}$ la derivada parcial de $u$ respecto de $t_{i}$ es
$$
  \frac{\partial u}{\partial t_{i}}=\frac{\partial u}{\partial x_{1}}\frac{\partial x_{1}}{\partial t_{i}} + \frac{\partial u}{\partial x_{2}}\frac{\partial x_{2}}{\partial t_{i}} + \dots + \frac{\partial u}{\partial x_{n}}\frac{\partial x_{n}}{\partial t_{i}}
$$
con $1\leq i\leq m$.

Existe también la forma matricial de la regla de la cadena que es mucho mas sencilla de ver y calcular, y además es muhco mas prolija y organizada (Moni usa un montón esta regla, y a mi también me parece mas práctica que la otra). La regla de la cadena en su forma matricial es como sigue:

::: {.callout-note title=Definición}
Sean $g:U  \subset \mathbb{R}^{n} \to \mathbb{R}^{m}$ y $f:V \subset \mathbb{R}^{m} \to \mathbb{R}^{p}$ funciones dadas tales que $g$ transforma $U$ en $V$, de forma que está definida $f\circ g$. Supongamos que $g$ es diferenciable en $\vec{x_{0}}$ y que $f$ es diferenciable en $\vec{y_{0}}=g(\vec{x_{0}})$. Entonces $f\circ g$ es diferenciable en $x_{0}$ y 
$$
  D(f\circ g)(\vec{x_{0}})=Df(g(\vec{x_{0}}))=Df(\vec{y_{0}})\cdot Dg(\vec{x_{0}})
$${#eq-regla-cadena}
:::

No voy a poner un ejemplo de regla de la cadena sin usar la forma matricial porque recomiendo mucho siempre usar esta forma.

::: {.callout-tip title=Ejemplo}
Dada $g(x,y)=(x^2+1, y^2)$ y $f(u,v)=(u+v,u,v^2)$, calcular la derivada de $f\circ g$ en $(1,1)$ usando la regla de la cadena.

- Primero identifiquemos las características de las funciones que nos dan:
  - Vemos que $g$ es una funcion $g:\mathbb{R}^{2} \to \mathbb{R}^{2}$, así que su matriz derivada pertenece a $\mathbb{R}^{2\times 2}$, osea que tiene dos filas y dos columnas.
  - Por otro lado, $f$ es una función $f:\mathbb{R}^{2} \to \mathbb{R}^{3}$, así que su matriz derivada pertenece a $\mathbb{R}^{3\times 2}$. Tiene tres filas y dos columnas.

- Calculemos ahora las matrices derivadas de ambas funciones
  - Para $g$ tenemos 
  $$
    Dg(x,y)=\begin{bmatrix}
      \frac{\partial f_{1}}{\partial x} & \frac{\partial f_{1}}{\partial y}\\[0.3cm]
      \frac{\partial f_{2}}{\partial x} & \frac{\partial f_{2}}{\partial y}
    \end{bmatrix}=\begin{bmatrix}
      2x & 0 \\
      0 & 2y
    \end{bmatrix}
  $$
  - Para $f$
  $$
    Df(u,v)=\begin{bmatrix}
      \frac{\partial f_{1}}{\partial u} & \frac{\partial f_{1}}{\partial v}\\[0.3cm]
      \frac{\partial f_{2}}{\partial u} & \frac{\partial f_{2}}{\partial v}\\[0.3cm]
      \frac{\partial f_{3}}{\partial u} & \frac{\partial f_{3}}{\partial v}
    \end{bmatrix}=\begin{bmatrix}
      1 & 1\\
      1 & 0\\
      0 & 2v
    \end{bmatrix}
  $$
- Lo siguiente que hay que hacer es evaluar las matrices de derivadas parciales en el punto que nos piden. Recordemos que estamos calculando $f\circ g$ en el punto $(1,1)$, que es lo mismo que decir $f(g(1,1))$.

  Entonces, a la matriz de derivadas de $g$ sí la evaluamos en el punto $(1,1)$, pero a la matriz de derivadas de $f$ la tenemos que evaluar en el punto que devuelve $g(1,1)$, que en este caso es $g(1,1)=(1^2+1,1^2)=(2,1)$. Tenemos que evaluar la matriz de derivadas de $f$ en el punto $(2,1)$.

  - $Dg(1,1)=\begin{bmatrix}
    2 & 0\\
    0 & 2
  \end{bmatrix}$
  - $Df(2,1)=\begin{bmatrix}
    1 & 1\\
    1 & 0\\
    0 & 2
  \end{bmatrix}$

- Por último, hacemos el producto de las matrices
$$
  Df(2,1)\cdot Dg(1,1)=\begin{bmatrix}
    1 & 1\\
    1 & 0\\
    0 & 2
  \end{bmatrix}\cdot \begin{bmatrix}
    2 & 0\\
    0 & 2
  \end{bmatrix}=\begin{bmatrix}
    2 & 2\\
    2 & 0\\
    0 & 4
  \end{bmatrix}
$$

- Esta matriz nos dice que la derivada de $f$ respecto de $x$ es $\frac{\partial f}{\partial x}=(2,2,0)$ (el vector de la columna 1), y que la derivada de $f$ respecto de $y$ es $\frac{\partial f}{\partial y}=(2,0,4)$ (el vector de la columna 2).
:::

## Teorema de Taylor
El hermoso (horrible) teorema de Taylor también aparece en funciones de varias variables. Este teorema, al igual que en análisis I, lo podemos usar para aproximar funciones. La forma de calcularlo es muy parecida a cuando lo hacíamos con una sola variable, solo que ahora tenemos que tener en cuenta que estamos trabajando con varias variables.

::: {.callout-warning title=Teorema icon=false}
**Teorema de Taylor para funciones de dos variables**

Sea $f: U \subset \mathbb{R}^{2} \to \mathbb{R}^{}$ una función diferenciable en el punto $P_{0}(x_{0},y_{0})$, podemos escribir el polinomio de Taylor de segundo orden como sigue
$$
f(x,y)=f(x_{0},y_{0})+f_{x}(x_{0},y_{0})\Delta x + f_{y}(x_{0},y_{0})\Delta y + \frac{1}{2}\left(\begin{bmatrix}
\Delta x & \Delta y
\end{bmatrix}\begin{bmatrix}
  f_{xx} & f_{xy}\\
  f_{yx} & f_{yy}
\end{bmatrix}\begin{bmatrix}
  \Delta x\\
  \Delta y
\end{bmatrix}\right) + Resto
$$
:::

::: {.callout-tip title=Ejemplo}
Dada la función $f(x,y)=\cos^{}(2x+\ln{y})$, obtener el polinomio de Taylor de segundo orden alrededor del punto $(x,y)=(0,1)$

- Primero calculemos todos los valores que tenemos que poner en la ecuación.
  $$
  \begin{aligned}
    f(0,1) &= \cos^{}(2\cdot 0+\ln{1})=1\\
    \Delta x &= x - 0 = x\\
    \Delta y &= y - 1\\
    \frac{\partial f}{\partial x} &= 2\cos^{}(2x+\ln{y})  \implies \frac{\partial f(0,1)}{\partial x} = 2\\
    \frac{\partial f }{\partial y} &= \frac{1}{y}\cos^{}(2x+\ln{y})  \implies \frac{\partial f(0,1)}{\partial y} = 1\\
    Hf &= \begin{bmatrix}
      4\cos^{}(2x+\ln{y}) & \frac{2}{y}\cos^{}(2x+\ln{y})\\
      \frac{2}{y}\cos^{}(2x+\ln{y}) & 0
    \end{bmatrix} \implies Hf(0,1)=\begin{bmatrix}
      4 & 2\\
      2 & 0
    \end{bmatrix}
  \end{aligned}
  $$

- Escribamos ahora el polinomio de Taylor con los datos que tenemos
$$
  p_{2}(x,y)=1 + 2(x) + 1(y-1) + \frac{1}{2}\left(\begin{bmatrix}
    x & y-1
  \end{bmatrix}\begin{bmatrix}
    4 & 2\\
    2 & 0
  \end{bmatrix}\begin{bmatrix}
    x\\
    y-1
  \end{bmatrix}\right)
$$

- Ahora resolvemos las cuentas y ya podemos escribir el polinomio
$$
\begin{aligned}
  p_{2}(x,y) &= 1+2x+y-1+\frac{1}{2}\left(4x^2+4x(y-1)\right)\\
  p_{2}(x,y) &= 2x+y+2x^2+2x(y-1)
\end{aligned}
$$
:::

## Derivación implícita
Cuando tenemos una función dada de forma implícita y queremos calcular sus derivadas parciales, podemos usar la regla de la cadena. Recordemos que una función está dada de forma explícita cuando se presenta de la forma $z=f(x,y)$. Otra forma que existe de definir a $z$ en función de $(x,y)$ es $F(x,y,z)=0$, que se llama forma implícita de $z$.

En esta @sec-implicita habíamos dicho que hay ocasiones en las que es imposible escribir una función que está en su forma implícita como una función explícita. En estos casos tenemos que usar la regla de la cadena sí o sí para calcular las derivadas parciales de la función y el **teorema de la función implícita** nos dice cuál es el procedimiento.

::: {.callout-warning title=Teorema icon=false}
**Teorema de la función implícita**

Dada una función $F$ definida en una bola alrededor del punto $(a,b,c)$, donde se cumple que $F(a,b,c)=0$, $F_{z}(a,b,c)\neq 0$, y $F_{x}$, $F_{y}$ y $F_{z}$ son continuas en un disco $D \subseteq \mathbb{R}^{2}$, la ecuación $F(x,y,z)=0$ define a $z$ como una función de $(x,y)$ en el disco $D$, y las derivadas parciales de $z$ están dadas por la ecuación 
$$
\begin{aligned}
  z_{x}(x,y)=-\frac{F_{x}(x,y,z(x,y))}{F_{z}(x,y,z(x,y))} && z_{y}(x,y)=-\frac{F_{y}(x,y,z(x,y))}{F_{z}(x,y,z(x,y))}
\end{aligned}
$${#eq-teorema-implicita}
:::

Este teorema lo podemos demostrar de forma sencilla de la siguiente manera.

Supongamos que $z=f(x,y)$ está dada implicitamente por la ecuación de fomra $F(x,y,z)=0$. Esto significa que $F(x,y,f(x,y))=0$ para todos los puntos $(x,y)$ que pertenecen al dominio de $f$. Si $F$ y $f$ son derivables, podemos derivar ambos miembros de la ecuación respecto de $x$ de la siguiente forma:
$$
  \frac{\partial F}{\partial x}\frac{\partial x}{\partial x} + \frac{\partial F}{\partial y}\frac{\partial y}{\partial x} + \frac{\partial F}{\partial z}\frac{\partial z}{\partial x} = 0
$$
Pero $\partial x/\partial x=1$ y $\partial y/\partial x = 0$. Sabemos que $z$ es en realidad una función de $(x,y)$, por eso $\partial z/\partial x$ no es necesariamente igual a cero. De esta manera, la ecuación anterior queda así:
$$
  \frac{\partial F}{\partial x} + \frac{\partial F}{\partial z}\frac{\partial z}{\partial x} = 0
$$

Si $\partial F/\partial z \neq 0$, podemos despejar $\partial z/\partial x$
$$
\begin{aligned}
  &\frac{\partial F}{\partial x} + \frac{\partial F}{\partial z}\frac{\partial z}{\partial x} = 0\\
  &\frac{\partial F}{\partial z}\frac{\partial z}{\partial x} = -\frac{\partial F}{\partial x}\\
  &\frac{\partial z}{\partial x} = -\frac{F_{x}}{F_{z}}
\end{aligned}
$$

Luego podemos repetir el mismo procedimiento para despejar $\partial z/\partial y$, solo que ahora hay que derivar respecto de $y$. El resultado final de ambos despejes es el siguiente:

::: {.callout-tip title=Ejemplo}
Sabiendo que $z=f(x,y)$ hallar $\frac{\partial z}{\partial x}$ y $\frac{\partial z}{\partial y}$ por derivación implícita de la función $F(x,y,z)=\sin^{}(xy)+\cos^{}(xz)-yz=0$.

- Primero buscamos las derivadas parciales de la función $F$.
$$
\begin{aligned}
  F_{x} &= \cos^{}(xy) - \sin^{}(xz)\\
  F_{y} &= \cos^{}(xy) - z\\
  F_{z} &= -\sin^{}(xz) - y
\end{aligned}
$$

- Ya podemos calcular las derivadas parciales de $z$ usando el teorema de la función implícita
$$
\begin{aligned}
  \frac{\partial z}{\partial x} &= -\frac{F_{x}}{F_{z}} = \frac{\cos^{}(xy) - \sin^{}(xz)}{\sin^{}(xz) + y}\\
  \frac{\partial z}{\partial y} &= -\frac{F_{y}}{F_{z}} = \frac{\cos^{}(xy) - z}{\sin^{}(xz) + y}
\end{aligned}
$$
:::

## Derivada direccional
Dada una función $z=f(x,y)$, las derivadas parciales $f_{x}$ y $f_{y}$ representan las razondes de cambio de $z$ en las direcciones de $x$ e $y$. Podríamos pensarlo como que representan las razones de cambio en las direcciones de los versores $\hat{i}$ y $\hat{j}$.

Supongamos ahora que queremos determinar la razón de cambio de $z$ en $(x_{0},y_{0})$ en la dirección de un vector unitario arbitrario $\hat{u}=\left\langle a,b \right\rangle$. Consideremos la superficie $S$ dada por la ecuación $z=f(x,y)$ y digamos que $z_{0}=f(x_{0},y_{0})$. De esta manera, el punto $P(x_{0},y_{0},z_{0})$ pertenece a la superficie $S$.

![Imagen sacada de @stewart2 [p. 947]](./imagenes/derivada-direccional.png)

El plano vertical que pasa por $P$ en la dirección $\hat{u}$ interseca a $S$ en la curva $C$. La pendiente de la recta tangente $T$ a $C$ en el punto $P$ es la razón de cambio de $z$ en la dirección de $\hat{u}$.

Si $Q(x,y,z)$ es otro punto en $C$ y $P^{\prime}$, $Q^{\prime}$ son las proyecciones de $P$, $Q$ en el plano $xy$, el vector $\vec{P^{\prime}Q^{\prime}}$ es paralelo a $\hat{u}$ y por lo tanto
$$
  \vec{P^{\prime}Q^{\prime}}=h\hat{u}=\left\langle ha,hb \right\rangle \qquad h \in \mathbb{R}^{}
$$
Así, $x-x_{0} = ha$, $y-y_{0}=hb$, entonces $x=x_{0}+ha$ e $y=y_{0}+hb$, con lo que podemos decir que
$$
  \frac{\Delta z}{h}=\frac{z-z_{0}}{h}=\frac{f(x_{0}+ha, y_{0}+hb)-f(x_{0},y_{0})}{h}
$$
Si calculamos el límite cuando $h \to 0$, obtenemos la razón de cambio de $z$ en la dirección de $\hat{u}$, que se conoce como **derivada direccional** de $f$ en la dirección $\hat{u}$.

::: {.callout-note title=Definición}
La derivada direccional de $f$ en $(x_{0},y_{0})$ en la dirección de un vector unitario $\hat{u}=\left\langle a,b \right\rangle$ es
$$
  D_{u}f(x_{0},y_{0})=\lim_{h \to 0}\frac{f(x_{0}+ha, y_{0}+hb)-f(x_{0},y_{0})}{h}
$${#eq-derivada-direccional}
si ese límite existe.
:::

Con esta definición podemos ver que si $\hat{u} = \hat{i} = \left\langle 1,0 \right\rangle$, entonces $D_{i}f=f_{x}$, y que si $\hat{u}=\hat{j}=\left\langle 0,1 \right\rangle$, entonces $D_{j}f=f_{y}$. Osea que, en realidad, las derivadas parciales respecto de $y$ y $x$ son casos especiales de las derivadas direccionales.

::: {.callout-warning title=Teorema icon=false}
Si $f$ es una función diferenciable de $x$ e $y$, entonces la derivada direccional de $f$ en la dirección del vector unitario $\hat{u}=\left\langle a,b \right\rangle$ es
$$
  D_{u}f(x,y)=f_{x}(x,y)a+f_{y}(x,y)b
$$
:::

Podemos demostrar el teorema anterior como sigue. Dado un punto fijo $(x_{0},y_{0})$, sea $g$ una función paramétrica de la recta tal que 
$$
g(t)=\begin{cases}
  x=x_{0}+t\cdot a\\
  y=y_{0}+t\cdot b
\end{cases}
$$
Podemos decir que $g$ es una función compuesta por $f(x,y)$ de manera que $g(t)=f(x(t),y(t))$. Como $f$ es diferenciable, se puede aplicar la regla de la cadena para obtener
$$
  g'(t)=f_{x}(x,y)x'(t) + f_{y}(x,y)y'(t) = f_{x}(x,y)a + f_{y}(x,y)b
$$
Si $t=0$, entonces $x=x_{0}$ e $y=y_{0}$, por lo tanto
$$
  g'(0)=f_{x}(x_{0},y_{0})a + f_{y}(x_{0},y_{0})b
$$
De acuerdo con la definición @eq-derivada-direccional, también es cierto que 
$$
\begin{aligned}
  g^{\prime}(0) &= \lim_{t \to 0}\frac{g(t)-g(0)}{t}\\
  g'(0) &= \lim_{t \to 0}\frac{f(x_{0}+ta, y_{0}+tb) - f(x_{0},y_{0})}{t}
\end{aligned}
$$
Así que queda demostrado que $D_{u}f(x,y)=f_{x}(x,y)a + f_{y}(x,y)b$.

::: {.callout-tip title=Ejemplo}
Hallar la derivada direccional de $f(x,y)=4-x^2-\frac{1}{4}y^2$ en el punto $(1,2)$ en la dirección de $\hat{u}=\left\langle \cos^{}(\frac{\pi}{3}),\sin^{}(\frac{\pi}{3}) \right\rangle$

$$
\begin{aligned}
  D_{u}f(x,y) &= f_{x}(x,y)\cos^{}(\frac{\pi}{3}) + f_{y}(x,y)\sin^{}(\frac{\pi}{3})\\
   &= (-2x)\cos^{}(\frac{\pi}{3}) + \left(-\frac{y}{2}\right)\sin^{}(\frac{\pi}{3})
\end{aligned}
$$
Evaluando en el punto $(1,2)$ obtenemos
$$
  D_{u}f(1,2)=(-2)\left(\frac{1}{2}\right) + (-1)\left(\frac{\sqrt[]{3}}{2}\right) = -1-\frac{\sqrt[]{3}}{2}
$$
:::

## El vector gradiente
Del teorema anterior, podemos ver que la derivada direccional de una función se puede escribir como el producto punto de dos vectores:
$$
\begin{aligned}
  D_{u}f(x,y) &= f_{x}(x,y)a + f_{y}(x,y)b\\
   &= \left(f_{x}(x,y),f_{y}(x,y)\right)\cdot \left\langle a,b \right\rangle\\
  D_{u}f(x,y) &= \left(f_{x}(x,y),f_{y}(x,y)\right)\cdot \hat{u}
\end{aligned}
$$

El primer vector en este producto recibe el nombre de **gradiente** de $f$ y se denota como $\nabla f$.

::: {.callout-note title=Definición}
Dada una función $f:U \subset \mathbb{R}^{n} \to \mathbb{R}^{}$, podemos definir el gradiente de la función, y lo denotamos como $\nabla f$, como un vector cuyas componentes son las derivadas parciales de todas sus variables independientes.
$$
  \nabla f=\left(\frac{\partial f}{\partial x_{1}}, \frac{\partial f}{\partial x_{2}}, \dots ,\frac{\partial f}{\partial x_{n}}\right)
$${#eq-gradiente}
:::

De esta manera, podemos escribir la derivada direccional de la siguiente manera
$$
  D_{u}f(x,y)=\nabla f \cdot \hat{u}
$$

::: {.callout-tip title=Ejemplo}
Hallar la derivada direccional de $f(x,y)=3x^2-2y^2$ en el punto $(-\frac{3}{4},0)$ en la dirección de $P(-\frac{3}{4}, 0)$ a $Q(0,1)$.

- Busquemos primero el vector unitario $\hat{u}$ que tiene dirección $PQ$
$$
\begin{aligned}
  \hat{u} &= \frac{\vec{PQ}}{\lVert\vec{PQ}\rVert} = \frac{(\frac{3}{4},1)}{\sqrt[]{\left(\frac{3}{4}\right)^2+1^2}}\\
  \hat{u} &= \frac{1}{5}(3,4)
\end{aligned}
$$

- Ahora buscamos el vector gradiente de $f$
$$
  \nabla f = \left(6x,-4y\right)
$$
  Y lo evaluamos en el punto $(-\frac{3}{4},0)$
  $$
    \nabla f\left(\frac{3}{4},0\right)=\left(-\frac{9}{2},0\right)
  $$

- Y con todo esto ya podemos calcular la derivada direccional
  $$
  \begin{aligned}
  D_{u}f\left(\frac{3}{4},0\right) &= \nabla f\left(\frac{3}{4},0\right)\cdot \hat{u}\\
   &= \left(-\frac{9}{2}, 0\right) \cdot \left(\frac{3}{4},\frac{4}{5}\right)\\
  D_{u}f\left(\frac{3}{4},0\right) &= -\frac{27}{10}
  \end{aligned}
  $$
:::

### Maximización de la derivada direccional
Como la derivada direccional $D_{u}f(\vec{x})$ es el producto escalar entre dos vectores $\nabla f(\vec{x})\cdot \hat{u}$, el **valor máximo** de la derivada direccional lo vamos a obtener cuando al dirección de $\nabla f(\vec{x})$ sea la misma que el versor $\hat{u}$. Esto es porque cuando dicho vectores tienen la misma dirección el producto escalar dá su valor máximo ya que el $\cos^{}(\theta)=1$. Cuando esto ocurre, el valor de la derivada direccional es el módulo del vector gradiente $D_{u}f(\vec{x})=\lVert\nabla f(\vec{x})\rVert$.

::: {.callout-tip title=Ejemplo}
La temperatura en grados Celsius en la superficie de una placa metálica es $T(x,y)=20-4x^2-y^2$, donde $x$ e $y$ se miden en centímetros. ¿En qué dirección a partir de $(2,-3)$ aumenta más rápido la temperatura? ¿Cuál es la tasa o ritmo de crecimiento?

Lo que nos pide la consigna es primero obtener la dirección de máximo creciemiento de la función $T$, que sabemos que es la dirección de $\nabla f$, y luego nos pide obtener la derivada direccional máxima en el punto $(2,-3)$.

- Busquemos el vector gradiente para encontrar la dirección de máximo crecimiento de $T$.
  $$
    \nabla T = \left(-8x, -2y\right)  \implies \nabla T(2,-3) = \left(-16,6\right)
  $$
  Para obtener la dirección normalizamos el vector gradiente en el punto $(2,-3)$.
  $$
    \hat{u} = \frac{1}{\sqrt[]{292}}\left(-16,6\right)
  $$
- La tasa de crecimiento es el valor de la derivada direccional máxima, que es la norma del vector gradiente en el punto $(2,-3)$.
  $$
    \lVert\nabla T(2,-3)\rVert = \sqrt[]{292}
  $$
:::

## Planos tangentes a superficies
Una de las propiedades importantes del vector gradiente es que siempre es perpendicular a la curva o superficie de nivel (dependiendo de la dimensión del dominio de la función). Esto lo podemos demostrar de la siguiente manera.

```{python}
#| label: fig-plano-tangente
#| fig-cap: El vector gradiente es normal a la superficie de nivel $F(x,y,z) = k$

# Superficie en el primer octante
theta = np.linspace(0, np.pi/2, 20)  # Restrict to first octant
phi = np.linspace(0, np.pi/2, 20)
theta, phi = np.meshgrid(theta, phi)
x = 2 * np.sin(theta) * np.cos(phi)
y = 2 * np.sin(theta) * np.sin(phi)
z = 2 * np.cos(theta)

# Plot de la superficie
surface = go.Surface(
  x=x, y=y, z=z,
  opacity=0.5,
  colorscale='Viridis',
  showscale=False,
  name='Superficie F(x,y,z)'
)

# Un punto P0 que pertenece a la superficie
point = go.Scatter3d(
  x=[1], y=[1], z=[np.sqrt(2)],
  mode='markers',
  marker=dict(size=5, color='black'),
  name='$P_{0}(x_{0},y_{0},z_{0})$'
)

# Curva sobre C sobre la superficie S en forma esférica, que pasa por el punto P0
phi = np.linspace(0, np.pi/2, 20)
theta = np.full_like(phi, np.pi/4)
curva_x = 2 * np.sin(phi) * np.cos(theta)
curva_y = 2 * np.sin(phi) * np.sin(theta)
curva_z = 2 * np.cos(phi)
curva = go.Scatter3d(
  x=curva_x, y=curva_y, z=curva_z,
  mode='lines',
  line=dict(color='red', width=4),
  name='$r(t)=(x(t),y(t),z(t))$'
)

# Recta tangente a la curva C
s = np.linspace(-0.5, 0.5, 20)
tangent_x = 1 + s
tangent_y = 1 + s
tangent_z = np.sqrt(2) - s * np.sqrt(2)
tangent = go.Scatter3d(
  x=tangent_x, y=tangent_y, z=tangent_z,
  mode='lines',
  line=dict(color='blue', width=4),
  name="Recta $r'(t)$"
)

# Gradient vector at (1, 1, sqrt(2))
gradient = go.Cone(
  x=[1], y=[1], z=[np.sqrt(2)],
  u=[2], v=[2], w=[2 * np.sqrt(2)],
  sizemode='absolute',
  anchor="tail",
  sizeref=0.5,
  colorscale="Reds",
  opacity=0.6,
  showscale=False,
  showlegend=True,
  name='Vector gradiente'
)

# Annotations for labeling
annotations = [
  # Sphere label
  dict(
    x=1.5, y=0.5, z=np.sqrt(4 - 1.5**2 - 0.5**2),
    text="Superficie F(x,y,z)",
    showarrow=True,
    arrowhead=2,
    ax=20, ay=-20
  ),
  # Point label
  dict(
    x=1, y=1, z=np.sqrt(2),
    text="P\u2080(x\u2080,y\u2080,z\u2080)", # \u2080 es equivalente a _0
    showarrow=True,
    arrowhead=2,
    ax=20, ay=-20
  ),
  # Curve label
  dict(
    x=0.5, y=0.5, z=np.sqrt(3.5),
    text="r(t\u2080)=(x(t\u2080),y(t\u2080),z(t\u2080))",
    font=dict(color="red"),
    showarrow=True,
    arrowhead=2,
    ax=20, ay=-20
  ),
  # Tangent line label
  dict(
    x=1.5, y=1.5, z=np.sqrt(2) - 0.5 * np.sqrt(2),
    text="Recta r'(t\u2080)",
    font=dict(color="blue"),
    showarrow=True,
    arrowhead=2,
    ax=20, ay=-20
  ),
  # Gradient vector label
  dict(
    x=5/4, y=5/4, z=5*np.sqrt(2)/4,
    text="Vector gradiente de F",
    font=dict(color="chocolate"),
    showarrow=True,
    arrowhead=2,
    ax=20, ay=-20
  )
]

# Create figure
fig = go.Figure(data=[surface, point, curva, tangent, gradient])
fig.update_layout(
    scene=dict(
        aspectmode='cube',
        xaxis=dict(range=[0, 2.5]),
        yaxis=dict(range=[0, 2.5]),
        zaxis=dict(range=[0, 2.5]),
        annotations=annotations
    ),
)
```

Supongamos que $S$ es una superficie de nivel con ecuación $F(x,y,z)=k$, y sea $P_{0}(x_{0},y_{0},z_{0})$ un punto en $S$. Sea $C$ cualquier curva de la superficie $S$ que pasa por el punto $P_{0}$. La función de la cruva $C$ la podemos escribir en su forma paramétrica de manera que $C=r(t)=\left(x(t),y(t),z(t)\right)$. Sea $t_{0}$ el valor paramétrico correspondiente a $P_{0}$; es decir, $r(t_{0})=\left(x_{0},y_{0},z_{0}\right)$. Como $C$ reside en $S$, cualquier punto $\left(x(t), y(t), z(t)\right)$, debe satisfacer la ecuación de $S$, es decir
$$
  F\left(x(t),y(t),z(t)\right)=k
$$

Si $x$, $y$ y $z$ son funciones derivables de $t$, y $F$ también es derivable, podemos derivar ambos lados de la ecuación respecto de $t$ usando la regla de la cadena como sigue:
$$
  \frac{\partial F}{\partial x}\frac{dx}{dt} + \frac{\partial F}{\partial y}\frac{dy}{dt} + \frac{\partial F}{\partial z}\frac{dz}{dt} = 0
$${#eq-derivada-Ft}

Pero habíamos visto recién que $\left(F_{x}, F_{y}, F_{z}\right)$ era el vector de gradiente de $F$, y también sabemos que $r'(t)=\left(x'(t), y'(t), z'(t)\right)$ es tangente a la superficie $S$. Podemos expresar la @eq-derivada-Ft de la siguiente manera
$$
  \left(F_{x}, F_{y}, F_{z}\right)\cdot \left(\frac{dx}{dt},\frac{dy}{dt},\frac{dz}{dt}\right) = 0
$$
$$
  \nabla F\cdot r'(t) = 0
$$
y analizarla en $t=t_{0}$
$$
  \nabla F(x_{0},y_{0},z_{0})\cdot r'(t_{0}) = 0
$${#eq-prod-gradiente-derivada}

La @eq-prod-gradiente-derivada establece que el vector gradiente en $P_{0}$ dado por $\nabla F(x_{0},y_{0},z_{0})$, es perpendicular al vector tangente $r'(t_{0})$, el cual es también perpendicular a cualquier curva $C$ en $S$ que pase por $P_{0}$. Osea que podemos afirmar que, si $\nabla F\neq \vec{O}$, entonces es perpendicular a la superficie $S$, por lo que es perpendicular al plano tangente a $S$ en el punto $P_{0}$. En otras palabras, el plano tangente a la superficie de nivel $F(x,y,z)=k$ en el punto $P_{0}$ es aquel cuyo vector normal es $\nabla F(x_{0},y_{0},z_{0})$ y pasa por el punto $P_{0}$.
$$
  \nabla F(x_{0},y_{0},z_{0})\cdot \vec{P_{0}P} = 0 \text{Ecuación del plano tangente a $S$}
$$

En el caso especial que la ecuación de una superficie $S$ sea de la forma $z=f(x,y)$, podemos definir la ecuación como 
$$
  F(x,y,z)=f(x,y)-z=0
$$
y cosiderarla como una superficie de nivel con $k=0$. De esta manera
$$
\begin{aligned}
  F_{x}(x_{0},y_{0},z_{0} &= f_{x}(x_{0},y_{0})\\
  F_{y}(x_{0},y_{0},z_{0} &= f_{y}(x_{0},y_{0})\\
  F_{z}(x_{0},y_{0},z_{0} &= -1
\end{aligned}
$$

::: {.callout-tip title=Ejemplo}
Hallar la ecuación del plano tangente y la recta normal a la superficie $z=e^{3x}\sin^{}(3y)$ en el punto $P(0,\frac{\pi}{6},1)$

- Esta ecuación está dada en la forma $z=f(x,y)$, así que la vamos a considerar como la superficie de nivel con $k=0$, de manera que $F(x,y,z)=e^{3x}\sin^{}(3y)-z=0$.

- Para encontrar la ecuación del plano todo lo que tenemos que hacer es encontrar el vector gradiente de $F$.
$$
\begin{aligned}
  F_{x}(x,y,z) = f_{x}(x,y) &= 3e^{3x}\sin^{}(3y) \implies F_{x}(0, \frac{\pi}{3}, 1) = 3\\
  F_{y}(x,y,z) = f_{y}(x,y) &= -3e^{3x}\cos^{}(3y) \implies F_{y}(0, \frac{\pi}{3}, 1) = 0\\
  F_{z} &= -1
\end{aligned}
$$

- Tenemos entonces el vector normal al plano, y un punto que pertenece al plano así que podemos encontrar su ecuación
$$
\begin{aligned}
  \pi &: \nabla F(0,\frac{\pi}{3},1)\cdot \left(x-0, y-\frac{\pi}{3}, z-1\right) = 0\\
   &: (3, 0, -1)\cdot (x-0,y-\frac{\pi}{3},z-1) = 0\\
  \pi &: 3x - z = -1
\end{aligned}
$$
:::

## Máximos y mínimos
::: {.callout-note title=Definición}
Una función de dos variables tiene un **máximo local** en $(a,b)$ si $f(x,y)\leq f(a,b)$ para todo $(x,y)$ en un disco abierto alrededor de $(a,b)$. El número $f(a,b)$ se llama **valor máximo local**.

Si $f(x,y)\geq f(a,b)$ para todo $(x,y)$ en un disco abierto de $(a,b)$, $f$ tiene un **mínimo local** en $(a,b)$ y $f(a,b)$ es un **mínimo local**.
:::

Si en la definición anterior las desigualdades son vállidas para todos los puntos $(x,y)$ del dominio de $f$, entonces $f$ tiene un **máximo absoluto** (o **mínimo absoluto**) en $(a,b)$.

Si $f$ tiene un máximo o un mínimo local en $(a,b)$ y las derivadas parciales existen, entonces $f_{x}(a,b)=0$ y $f_{y}(a,b)=0$. En otras palabras, si hay un máximo o un mínimo en $(a,b)$, el gradiente de $f$ es el vector nulo $\nabla f(a,b)=\vec{O}$.

Un **punto crítico** de $f$ es cuando $f_{x}(a,b)=0$ y $f_{y}(a,b)=0$, o si al menos una de las derivadas parciales no existe. Todos los máximos y mínimos de $f$ son puntos críticos, pero no todos los puntos críticos son máximos o mínimos de $f$.

::: {.callout-tip title=Ejemplo}
Sea $f(x,y)=x^2+y^2-2x-6y+14$, calcular los extremos de la función.

- Primero calculamos las derivadas parciales
$$
\begin{aligned}
  f_{x}(x,y) = 2x-2 && f_{y}(x,y) = 2y-6
\end{aligned}
$$

- Ahora tenemos que buscar los puntos críticos de la función. Para eso igualamos a cero las derivadas parciales y resolvemos el sistema de ecuaciónes
$$
  \left\{
  \begin{aligned}
    2x - 2 = 0\\
    2y - 6 = 0
  \end{aligned}
  \right. \implies \left\{
  \begin{aligned}
    x = 1\\
    y = 3
  \end{aligned}
  \right.
$$
  El único punto crítico que encontramos es el $(1,3)$.

- Ahora evaluamos la función en el punto crítico. Conviene completar los cuadrados para hacer los cálculos mas sencillos
$$
  f(x,y)=(x-1)^2+(y-3)^2+4
$$
Al evaluar la función en el punto $(1,y)$ nos queda $(y-3)^2\geq 0,  \forall y \in \mathbb{R}^{}$. Cuando evaluamos en el punto $(x,3)$ obetenemos $(x-1)^2\geq 0,  \forall x \in \mathbb{R}^{}$. Esto nos dice que la función crece en la dirección de $x$ y también en la dirección de $y$ a partir del punto $(1,3)$, por lo que $f(1,3)=4$ es mínimo absoluto de $f$. 

```{python}
#| label: fig-ej1-extremos
#| fig-cap: Visualización de la función $f(x,y)=(x-1)^2+(y-3)^2+4$ y su punto crítico en $f(1,3)$.

fig = go.Figure()

x = np.linspace(-3, 5)
y = np.linspace(0, 6)
x, y = np.meshgrid(x, y)
z = (x - 1)**2 + (y - 3)**2 + 4

fig.add_trace(go.Surface(
  x=x, y=y, z=z,
  colorscale="Viridis",
  showscale=False,
  opacity=0.6,
  cmin=4,
  cmax=13,
))

fig.add_trace(go.Scatter3d(
  x=[1], y=[3], z=[4],
  mode='markers+text',
  marker=dict(size=4, color='red'),
  showlegend=False,
))

fig.update_layout(
  scene=dict(
    xaxis=dict(range=[-3, 5]),
    yaxis=dict(range=[0, 6]),
    zaxis=dict(range=[0, 13]),
    annotations=[
      dict(
        x=1, y=3, z=4,
        text="P(1,3,4)",
        font=dict(color="red"),
        ay=50
      ),
    ]
  )
)
```
:::

::: {.callout-tip title=Ejemplo}
Sea la función $f(x,y)=y^2-x^2$, calcular sus valores extremos.

$$
\begin{aligned}
  f_{x}(x,y) = -2x && f_{y}(x,y) = 2y
\end{aligned}
$$

Las derivadas se hacen cero cuando $x=y=0$, así que tenemos un solo punto crítico en el $(0,0)$.
Sin embargo, al analizar la función en ese punto vemos que en un sentido crece, y en otro decrece: $f(0,y)=y^2\geq 0,  \forall y \in \mathbb{R}^{}$, pero $f(x,0)=-x^2\leq 0, \forall x \in \mathbb{R}^{}$. En consecuencia, todos los discos alrededor del punto $(0,0)$ contienen puntos donde $f$ adopta valores positivos, así como puntos en los que $f$ adopta valores negativos. Por lo tanto, $f(0,0)=0$ no puede ser ni un máximo ni un mínimo de $f$. Es un **punto silla**.

```{python}
#| label: fig-ej2-extremos
#| fig-cap: Visualización de la función $f(x,y)=y^2-x^2$ y su punto silla en $f(0,0)$.

fig = go.Figure()

x = np.linspace(-5, 5)
y = np.linspace(-5, 5)
x, y = np.meshgrid(x, y)
z = y**2 - x**2

fig.add_trace(go.Surface(
  x=x, y=y, z=z,
  opacity=0.6,
  showscale=False,
  colorscale="Viridis"
))

fig.add_trace(go.Scatter3d(
  x=[0], y=[0], z=[0],
  mode="markers+text",
  marker=dict(size=4, color="red"),
  showlegend=False
))

fig.update_layout(
  scene=dict(
    annotations=[
      dict(
        x=0, y=0, z=0,
        text="P(0,0,0)",
        font=dict(color="red"),
      )
    ]
  )
)
```
:::

En los ejemplos que vimos recién es fácil determinar los extremos relativos porque cada una de las funciones estaba dada, o se podía expresar, en forma de cuadrado perfecto. Para funciones mas complicadas existen métodos, como el de la segunda derivada, para determinar los extremos de una función.

::: {.callout-warning title=Teorema icon=false}
**Teorema del criterio de las segundas derivadas parciales**

Sea $f$ una función con segundas derivadas parciales continuas en una región abierta que contiene un punto $(a,b)$ para el cual
$$
\begin{aligned}
  f_{x}(a,b) = 0  && \text{y} && f_{y}(a,b)=0
\end{aligned}
$$
Para buscar los extremos relativos de $f$, podemos armar el **Hessiano** en el punto $(a,b)$ ($Hf(a,b)$) y calcular su determinante.

- Si $\det{Hf} > 0$ y $f_{xx}(a,b)>0$, entonces $f(a,b)$ es un mínimo local.
- Si $\det{Hf} > 0$ y $f_{xx}(a,b)<0$, entonces $f(a,b)$ es un máximo local.
- Si $\det{Hf} < 0$, entonces $f(a,b)$ es un punto silla.
- Si $\det{Hf} = 0$, entonces este método no sirve ya que no aporta información útil.
:::

::: {.callout-tip title=Ejemplo}
Encontrar los valores máximos y mínimos locales, y los puntos silla de la función $f(x,y)=x^4 + y^4 - 4xy + 1$.

- Primero buscamos los puntos críticos
$$
\begin{aligned}
  f_{x}(x,y) = 4x^3 - 4y && f_{y}(x,y) = 4y^3 - 4x
\end{aligned}
$$
  Al igualar a cero las derivadas parciales se obtiene el siguiene sistema de ecuaciones:
  $$
    \left\{
    \begin{aligned}
      4(x^3 - y) = 0\\
      4(y^3 - x) = 0
    \end{aligned}
    \right. \implies \left\{
    \begin{aligned}
      x^3 = y\\
      y^3 = x
    \end{aligned}
    \right. \implies (x^3)^3 - x = 0
  $$
  $$
     \implies 0 = x(x^8 - 1) = x(x^4 - 1)(x^4 - 1) = x(x^2 - 1)(x^2 + 1)(x^4 - 1)
  $$
  De manera que hay tres raíces reales: $x=\left\{0, 1, -1\right\}$. Los tres puntos críticos son $(0,0)$, $(1,1)$, y $(-1,-1)$. Fijarse que los puntos en los que $x$ e $y$ tienen distinos valores o distintos signos se descartan porque sabemos que $x^3=y$.

- Calculemos ahora las segundas derivadas para poder armar el Hessiano:
  $$
  \begin{aligned}
    f_{xx}(x,y) = 12x^2 && f_{xy}(x,y) = -4 && f_{yx}(x,y) = -4 && f_{yy}(x,y) = 12y^2
  \end{aligned}
  $$

  El Hessiano y su determinante nos quedan así:
  $$
  \begin{aligned}
    Hf(x,y) = \begin{bmatrix}
      12x^2 & -4\\
      -4 & 12y^2
    \end{bmatrix} && ,\det{Hf(x,y)} = 144x^2y^2 - 16
  \end{aligned}
  $$
  Cuando analizamos la $\det{Hf}$ en el punto $(0,0)$ obtenemos $\det{Hf(0,0)} = -16 < 0$, y el teorema de la segunda derivada nos dice que el $f(0,0)=2$ es un punto silla.

  Si analizamos la $\det{Hf}$ en el punto $(1,1)$ obtenemos $\det{Hf(1,1)} = 128 > 0$. Tenemos que mirar entonces el valor de $f_{xx}(1,1)$, que es igual a $12$, así que según el teorema, el punto $f(1,1)=12$ es un mínimo local. En el punto $(1,1)$ la determinante del Hessiano nos vuelve a dar $128$, y $f_{xx}(1,1)=12$, así que $f(-1,-1)=12$ es también un mínimo local.

```{python}
#| label: fig-ej-teorema-2da-derivada
#| fig-cap: Visualización de la función $f(x,y)=x^4+y^4-4xy+2$ y sus puntos críticos.

x = np.linspace(-2, 2)
y = np.linspace(-2, 2)
x, y = np.meshgrid(x, y)
z = x**4 + y**4 - 4*x*y + 2
z = np.minimum(z, 5.2)

superficie = go.Surface(
  x=x, y=y, z=z,
  colorscale="Viridis",
  opacity=0.6,
  showscale=False,
)

puntos_criticos = go.Scatter3d(
  x=[-1, 0, 1], y=[-1, 0, 1], z=[0, 2, 0],
  mode="markers+text",
  marker=dict(size=4, color="red")
)

fig = go.Figure(data=[superficie, puntos_criticos])

fig.update_layout(
  scene=dict(
    zaxis=dict(range=[0,5]),
    aspectmode="cube",
    annotations=[
      dict(
        x=-1, y=-1, z=0,
        text="P(-1,-1,0)",
        font=dict(
          color="red",
        )
      ),
      dict(
        x=1, y=1, z=0,
        text="P(1,1,0)",
        font=dict(
          color="red",
        )
      ),
      dict(
        x=0, y=0, z=2,
        text="P(0,0,2)",
        font=dict(
          color="red",
        )
      ),
    ]
  )
)
```
:::

### Valores máximos y mínimos absolutos
Para una función $f$ de una variable, el teorema de los vlaores extremos establece que si $f$ es continua en un intervalo cerrado $\left[a,b\right]$, $f$ tiene un valor mínimo absoluto y un máximo absoluto. Esos valores se determinan evaluando $f$ no solo en los puntos críticos, sino también en los puntos extremos $a$ y $b$.

Lo mismo que pasa en las funciones escalares, pasa para las funciones de varias variables.

::: {.callout-warning title=Teorema icon=false}
**Teorema de los valores extremos para funciones de dos variables**

Si $f$ es continua en un conjunto cerrado y acotado $D$ en $\mathbb{R}^{2}$, entonces $f$ alcanza un valor máximo absoluto $f(x_{1}, y_{1})$ y un valor mínimo absoluto $f(x_{2},y_{2})$ en algunos puntos en $D$.
:::

Podemos entonces extender el teorema de los valores extremos relativos

Para determinar los valores máximo y mínimo absolutos de una función continua $f$ en un conjunto cerrado y acotado $D$:

1. Determinamos los valores de $f$ en los puntos críticos de $f$ en $D$.
2. Determinamos las valores extremos de $f$ en la frontera de $D$.
3. El mayor de los valores de los pasos 1 y 2 es el valor máximo absoluto; el menor de esos valores es el mínimo absoluto.

::: {.callout-tip title=Ejemplo}
Hallar los valores máximo y mínimo absoluto de la función $f(x,y)=x^2 - 2xy + 2y$ en el rectángulo $D=\left\{(x,y) \;/\; 0\leq x\leq 3 \land 0\leq y\leq 2\right\}$

- Buscamos los puntos críticos
  $$
  \begin{aligned}
    f_{x}=2x-2y=0 && f_{y}(x,y)=-2x + 2 = 0
  \end{aligned}
  $$

  El único punto crítico es el $(1,1)$, y el valor de $f$ ahí es $f(1,1)=1$.

- El siguiente paso es determinar los valores extremos de $f$ en la forntera de $D$, que en este caso son los cuatro segmentos de recta $L_{1},L_{2},L_{3},L_{4}$ que delimitan el cuadrado $D$.

```{python}
#| label: fig-ej-extremo-absoluto
#| fig-cap: Visualización de la región $D$.

# Este gráfico me lo hizo GrokAI. Tremendo.
# Define the vertices of the rectangle
x = [0, 3, 3, 0, 0]  # Close the polygon by returning to the start
y = [0, 0, 2, 2, 0]

# Create the plot
plt.figure(figsize=(6, 4))
plt.plot(x, y, 'b-', label='Boundary')  # Plot the rectangle boundary

# Fill the interior with a soft color (e.g., light blue)
plt.fill(x, y, color='lightblue', alpha=0.3)

# Add labels for each side
plt.text(1.5, -0.1, '$L_1$', ha='center', va='top')
plt.text(3.1, 1, '$L_2$', ha='left', va='center')
plt.text(1.5, 2.1, '$L_3$', ha='center', va='bottom')
plt.text(-0.1, 1, '$L_4$', ha='right', va='center')

# Set axis limits and labels
plt.xlim(-0.5, 3.5)
plt.ylim(-0.5, 2.5)
plt.xlabel('x')
plt.ylabel('y')
plt.grid(True)
plt.legend()

# Display the plot
plt.show()
```

  - El segmento $L_{1}$ está dado por la ecuación $L_{1}:=\begin{cases}
    y = 0 \\
    0 \leq x\leq 3
  \end{cases}$. Si evaluamos la recta $L_{1}$ en la ecuación $f$ obtenemos:
  $$
  \begin{aligned}
    f(x,0)=x^2 && 0\leq x\leq 3
  \end{aligned}
  $$
  El valor mínimo de esta función es $f(0,0)=0$ y el máximo es $f(3,0)=9$.

  - Para $L_{2}$ que:
  $$
  \begin{aligned}
    f(3,y) = 9 - 4y && 0\leq y\leq 2
  \end{aligned}
  $$
  El valor mínimo es $f(3,0)=9$ y su valor mínimo es $f(3,2)=1$.

  - Para $L_{3}$ tenemos:
  $$
  \begin{aligned}
    f(x,2)=x^2-4x+4 && 0\leq x\leq 3
  \end{aligned}
  $$
  El valor mínimo de esta función es $f(2,2)=0$ y el valor máximo es $f(0,2)=4$.

  - Por último, para $L_{4}$ tenemos:
  $$
  \begin{aligned}
    f(0,y)=2y && 0\leq y\leq 2
  \end{aligned}
  $$
  que tiene valor mínimo $f(0,0)=0$ y valor máximo $f(0,2)=4$.

- Ahora nos fijamos todos los valores que obtuvimos y determinamos los máximos y mínimos. En este caso, el valor máximo que obtubimos fue $f(3,0)=9$ y el valor mínimo es $f(0,0)=f(2,2)=0$. Estos valores son extremos absolutos.

```{python}
#| label: fig-ej-extremos-absolutos
#| fig-cap: Visualización de la función $f(x,y)=x^2-2xy+2y$ y sus valores extremos absolutos dentro de la región $D$.

x = np.linspace(0, 3)
y = np.linspace(0, 2)
x, y = np.meshgrid(x, y)
z = x**2 - 2*x*y + 2*y

superficie = go.Surface(
  x=x, y=y, z=z,
  colorscale="Viridis",
  showscale=False,
  opacity=0.6
)

puntos = go.Scatter3d(
  x=[0, 2, 3], y=[0, 2, 0], z=[0, 0, 9],
  mode="markers",
  marker=dict(size=4, color="red"),
)

fig = go.Figure(data=[superficie, puntos])

fig.update_layout(
  scene=dict(
    aspectmode="cube",
    annotations=[
      dict(
        x=0, y=0, z=0,
        text="P(0,0,0)",
        font=dict(
          color="red",
        )
      ),
      dict(
        x=3, y=0, z=9,
        text="P(3,0,9)",
        font=dict(
          color="red",
        )
      ),
      dict(
        x=2, y=2, z=0,
        text="P(2,2,0)",
        font=dict(
          color="red",
        )
      ),
    ]
  )
)
```
:::

## Multiplicadores de Lagrange
Una de las mayores aplicaciones de los extremos de las funciones es resolver problemas de optimización. Cuando queremos optimizar una función $f(x,y)$ vamos a necesitar encontrar sus extremos, pero además vamos a estar sujetos a restricciones del tipo $g(x,y)=k$. Un ejemplo de una situación en la que pasa esto es cuando queremos calcular las dimensiones de un depósito cilíndrico, y queremos que tenga un cierto volumen $k$, y que el área total sea mínima. En este caso, la función que estamos intentando optimizar es la del área de cilíndro, y la restricción es el volúmen del mismo igual a $k$.

### Una restricción
Para entender este método conviene primero analizarlo para funciones de dos variables, y una vez que lo entdemos geométricamente podemos estudiarlo para funciones de tres variables. entonces, supongamos que tenemos una funcion $f(x,y)$ y queremos encontrar los valores extremos cuando el punto $(x,y)$ está restringido a residir en la curva de nivel $g(x,y)=k$.

![Imagen sacada de @stewart2 [p. 971]](./imagenes/intro-multiplicadores-lagrange.png){#fig-intro-lagrange}

En la @fig-intro-lagrange podemos ver la curva $g(x,y)=k$ y vaias curvas de nivel de $f$, dadas por $f(x,y)=c$, donde $c=\left\{7,8,9,10,11\right\}$. Maximizar $f(x,y)$ sujeta a $g(x,y)=k$ consiste en encontrar el mayor valor de $c$ para el cual la curva $f(x,y)=c$ interseca a $g(x,y)=k$. Podemos ver que esto sucede cuando dichas curvas apenas se tocan, y en ese punto comparten la misma recta tangente. Esto significa que las rectas normales a cada curva en el punto $(x_{0},y_{0})$ donde se tocan son idénticas. Podemos decir entonces que los vectores gradientes son paralelos: es decir $\nabla f(x_{0},y_{0})=\lambda\nabla g(x_{0},y_{0})$ con $\lambda \in \mathbb{R}^{}$.

El mismo argumento aplica cuando queremos encontrar valores extremos de $f(x,y,z)$ sujeta a la restricción $g(x,y,z)=k$, solo que ahora en vez de pensar en curvas de nivel tenemos que pensar en superficies de nivel. Como los vectores gradiente de $f$ y $g$ son paralelos, podemos decir que si $\nabla g\neq \vec{O}$, existe un $\lambda \in \mathbb{R}^{}$ tal que
$$
  \nabla f(x_{0},y_{0},z_{0})=\lambda\nabla g(x_{0},y_{0},z_{0})
$$  
El número real $\lambda$ se llama **multiplicador de Lagrange**.

::: {.callout-warning title="Método de los multiplicadores de Lagrange" icon=false}
Para determinar los valores máximo y mínimo de $f(x,y,z)$ sujetos a la restricción $g(x,y,z)=k$ (suponiendo que esos valores existen y que $\nabla g(x_{0},y_{0},z_{0})\neq \vec{O}$):

1. Determinamos todos los valores de $x, y, z, \lambda$ tales que 
  $$
    \left\{
    \begin{aligned}
      \nabla f(x,y,z) &= \lambda\nabla g(x,y,z)\\
      g(x,y,z) &= k
    \end{aligned}
    \right.
  $$

2. Evaluamos $f$ en todos los puntos $(x,y,z)$ que resulten del paso anterior. El mayor de esos valores es el valor máximo de $f$; el menor es el valor mínimo de $f$.

Los valores que tome $\lambda$ no son importantes.
:::

::: {.callout-tip title=Ejemplo}
Se quiere armar una caja rectangular sin tapa con $12m^2$ de cartón. Determinar el volumen máximo de la caja.

- Lo primero que tenemos que hacer en este tipo de ejercicios es identificar cuál es la función que queremos optimizar, y cuál es nuestra restricción.
  
  ```{python}
  #| label: fig-paralelepipedo
  #| fig-cap: Una caja rectangular sin tapa
  #| fig-width: 10
  #| fig-height: 8
  #| dpi: 300

  from mpl_toolkits.mplot3d import Axes3D
  from mpl_toolkits.mplot3d.art3d import Poly3DCollection

  fig = plt.figure(figsize=(10, 8), dpi=300)
  ax = fig.add_subplot(111, projection='3d')

  largo, ancho, alto = 2, 3, 4

  faces = [
      [[0, 0, 0], [largo, 0, 0], [largo, ancho, 0], [0, ancho, 0]],
      [[0, 0, 0], [largo, 0, 0], [largo, 0, alto], [0, 0, alto]],
      [[0, ancho, 0], [largo, ancho, 0], [largo, ancho, alto], [0, ancho, alto]],
      [[0, 0, 0], [0, ancho, 0], [0, ancho, alto], [0, 0, alto]],
      [[largo, 0, 0], [largo, ancho, 0], [largo, ancho, alto], [largo, 0, alto]]
  ]

  colors = ['lightcoral', 'lightgoldenrodyellow', 'lightseagreen', 'lavender', 'mistyrose']

  face_collection = Poly3DCollection(faces, linewidth=0.5, edgecolors='k', alpha=0.3)
  face_collection.set_facecolor(colors)

  ax.add_collection3d(face_collection)

  ax.set_xlabel('X (Largo)', labelpad=1)
  ax.set_ylabel('Y (Ancho)', labelpad=1)
  ax.set_zlabel('Z (Alto)', labelpad=1)
  # ax.set_xlim(1, 3)
  # ax.set_ylim(-1, 3)
  # ax.set_zlim(-1, 3)

  ax.set_xticks([])
  ax.set_yticks([])
  ax.set_zticks([])

  ax.view_init(elev=25, azim=-60)

  ax.legend()

  plt.tight_layout()

  plt.show()
  ```
  - En este caso nos piden encontrar el columen máximo, así que la función que tenemos que optimizar es la del volúmen de un paralelepípedo. Vamos a definir $x$, $y$ y $z$ como el largo, ancho y alto de la caja, de manera que la función del volúmen nos queda
    $$
      V(x,y,z)=xyz
    $$
  - Por otro lado, la restricción que nos dan es que solo tenemos $12m^2$ de cartón para armar la caja. Nos están diciendo que el área de la misma es igual a 12. Como la caja no tiene tapa, con el cartón vamos a tener que cubrir la cara $xy$ (piso de la caja) una sola vez, la cara $yz$dos veces (los lados izquierdo y derecho de la caja) y la cara $xz$ también dos veces (las caras del frente y atrás de la caja). La ecuación del área, que es nuestra restricción nos queda así:
    $$
      g(x,y,z)=2xz + 2yz + xy = 12
    $$

- Como ya sabemos cuáles son nuestras funciones, podemos armar el sistema de ecuaciónes y resolver
  $$
  \left\{
  \begin{aligned}
    \nabla V(x,y,z) &= \lambda\nabla g(x,y,z)\\
    g(x,y,z) &= k
  \end{aligned}
  \right.
  $$
  $$
    \implies \left\{
  \begin{aligned}
    V_{x} = \lambda g_{x}\\
    V_{y} = \lambda g_{y}\\
    V_{z} = \lambda g_{z}\\
    2xz + 2yz + xy = 12
  \end{aligned}
  \right. \implies \left\{
  \begin{aligned}
    yz = \lambda(2z+y) && (1)\\
    xz = \lambda(2z+x) && (2)\\
    xy = \lambda(2x+2y) && (3)\\
    2xz + 2yz + xy = 12 && (4)\\
  \end{aligned}
  \right.
  $$
  - Lo primero que podemos descartar de este sistema es $\lambda=0$, ya que si esto es cierto implicaría que $yz=xz=xy$ que sabemos que no es cierto por la ecuación (4). Por otro lado, podemos multiplicar (1) por $x$, (2) por $y$ y (3) por $z$ para que nos queden los lados izquierdos de las ecuaciones (1), (2) y (3) todos iguales.
  $$
    \left\{
    \begin{aligned}
      xyz = \lambda(2xz+xy) && (5)\\
      yxz = \lambda(2yz+yx) && (5)\\
      zxy = \lambda(2zx+yz) && (5)\\
      2xz + 2yz + xy = 12 && (4)\\
    \end{aligned}
    \right.
  $$
  - De (6) y (7) podemos decir que 
  $$
    2xz + xy = 2yz + xy
  $$
  que nos dice que $xz=yz$. Pero $z\neq 0$ porque el volúmen de la caja no puede ser cero, así que $x=y$.
  - De (7) y (8) tenemos que
  $$
    2yz + xy = 2xz + 2yz
  $$
  de donde sale que $xy=2xz$, y por lo tanto $y=2z$ ya que $x\neq 0$. Y ya resolvimos nuestro sistema de ecuaciones. Ahora podemos poner $x=y=2z$ en (4) y obtenemos
  $$
    4z^2 + 4z^2 + 4z^2 = 12
  $$
  - Como $x$, $y$ y $z$ son positivas (porque no podemos tener volúmen o área negativa), se tiene que $z=1$, así que $x=y=2$.
  
- El vólumen máximo de una caja rectangular sin tapa con un área total de $12m^2$ es $V(x,y,z)=2\cdot 2\cdot 1=4m^3$.
:::

### Dos restricciones
También nos pueden pedir que encontremos los valores máximo y mínimo de una función $f(x,y,z)$ sujeta a dos restricciones de la forma $g(x,y,z)=k$ y $h(x,y,z)=c$.

Cuando teníamos el caso de una sola restricción habíamos dicho que $\nabla f = \lambda\nabla g$ y esto lo podemos pensar como que $\nabla f$ es combinación lineal de $\nabla g$. Exactamente el mismo concepto es el que tenemos que aplicar enel caso de dos restricciones: $\nabla f$ debe ser combinación lineal de los vectores $\nabla g$ y $\nabla h$. Esto siginifica que el vector gradiente $\nabla f(x_{0},y_{0},z_{0})$ está en el plano determinado por $\nabla g(x_{0},y_{0},z_{0})$ y $\nabla h(x_{0},y_{0},z_{0})$.
$$
  \nabla f(x_{0},y_{0},z_{0}) = \lambda\nabla g(x_{0},y_{0},z_{0}) + \mu\nabla h(x_{0},y_{0},z_{0})
$$
Los valores $\lambda$ y $\mu$ son denominados multiplicadores de Lagrange.

Al haber ahora dos restricciones, el sistema de ecuaciones que vamos a tener va a ser un sistema de cinco ecuaciones con cinco incógnitas.
$$
  \left\{
  \begin{aligned}
    f_{x}=\lambda g_{x} + \mu h_{x}\\
    f_{y}=\lambda g_{y} + \mu h_{y}\\
    f_{z}=\lambda g_{z} + \mu h_{z}\\
    g(x,y,z)=k\\
    h(x,y,z)=c
  \end{aligned}
  \right.
$$

::: {.callout-tip title=Ejemplo}
Encontrar el valor máximo de la función $f(x,y,z)=x+2y+3z$ en la curva de intersección del plano $x-y+z=1$ y el cilindro $x^2+y^2=1$.

- Planteamos el sistema de ecuaciones:
$$
  \left\{
  \begin{aligned}
    1 = \lambda + \mu2x && (1)\\
    2 = -\lambda + \mu2y && (2)\\
    3 = \lambda && (3)\\
    x - y + z = 1 && (4)\\
    x^2 + y^2 = 1 && (5)
  \end{aligned}
  \right.
$$

- De (3) sale $\lambda = 3$, que si lo ponemos en (1) nos queda $\mu2x=-2 \implies x=-1/\mu$. Podemos hacer lo mismo en (2) para obtener $y=5/(2\mu)$. Ahora podemos sustituir $x$ e $y$ en (5):
  $$
    \frac{1}{\mu^2} + \frac{25}{4\mu^2} = 1
  $$
  y por lo tanto, $\mu^2=\frac{29}{4} \implies \mu=\pm\sqrt[]{29}/2$. Entonces $x=\mp2/\sqrt[]{29}$, $y=\pm5/\sqrt[]{29}$ y podemos meter estos valores en (4) de manera que $z=1-x+y=1\pm7/\sqrt[]{29}$. Los valores correspondientes de $f$ son:
  $$
    \mp\frac{2}{\sqrt[]{29}} + 2\left(\pm\frac{5}{\sqrt[]{29}}\right) + 3\left(1\pm\frac{7}{\sqrt[]{29}}\right) = 3\pm\sqrt[]{29}
  $$
  El valor máximo de $f$ en la curva dada es $3+\sqrt[]{29}$
:::

# Integrales múltiples
Último tema



